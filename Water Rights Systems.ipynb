{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scripts scrap data from the Utah Water Rights website, saves the data to text files, then parses the text files into a MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "from urllib2 import urlopen\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as tick\n",
    "import scipy.stats as sp\n",
    "import statsmodels.api as sm\n",
    "from pandas.stats.api import ols\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from pylab import rcParams\n",
    "import platform\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import urllib\n",
    "import HTMLParser\n",
    "from cStringIO import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose output routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#route = 'C:/PROJECTS/WR_DATA/'\n",
    "wellpath = 'D:/PROJECTS/WR_DATA/RawWellogs/'\n",
    "syspath = 'D:/PROJECTS/WR_DATA/RawSystems/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser and Scraper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    # opens webpage for use in BeautifulSoup    \n",
    "    html = urlopen(url).read()\n",
    "    return BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Log Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapes well Logs from Water Rights website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Water Rights win number to begin search\n",
    "winbegin = 34000\n",
    "space = 1000\n",
    "winend = winbegin + space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while winbegin < 60000:\n",
    "       \n",
    "    # opens waterrights webpage by win   \n",
    "    for i in range(winbegin,winend):\n",
    "        try:\n",
    "            win = str(i)\n",
    "            soup = make_soup('http://waterrights.utah.gov/cgi-bin/docview.exe?Folder=welllog'+str(i))\n",
    "            souplist = soup.find('a', href=re.compile('^http://waterrights.utah.gov/docSys/v907/.*'))['href']\n",
    "            soupsite = make_soup(souplist)\n",
    "            souptext = soupsite.get_text()\n",
    "            g = path + 'log' + str(win).zfill(5) + '.txt'    \n",
    "            b = open(g, 'w')\n",
    "            b.write(souptext.encode('utf-8'))\n",
    "            b.close()\n",
    "        except TypeError:        \n",
    "            pass\n",
    "    \n",
    "    winbegin = winend\n",
    "    winend = winbegin + space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water System Use Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: http://www.waterrights.utah.gov/wateruse/WaterUseList.asp<br/>\n",
    "Example Pages of Input:<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=Indview&SYSTEM_ID=11247<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=Mgtview&SYSTEM_ID=11228<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def systemscraper(winbegin,winfinish,space,prefix,path):\n",
    "    '''\n",
    "    Systematically progresses though integer id numbers at the end of Water Rights URL to find system pages, \n",
    "    then saves those pages to text files.\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    winbegin = integer value to start search\n",
    "    space = number of integers to search at a time\n",
    "    winfinish = integer value to end search\n",
    "    prefix = subset of systems to search (Modinfo= value in URL); can be Pws, Ind, or Mgt\n",
    "    path = place to store resulting text files\n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    text files in path labeled with corresponding integer values\n",
    "    '''\n",
    "    winend = winbegin + space\n",
    "\n",
    "    while winbegin < winfinish:\n",
    "\n",
    "        systemnm = []\n",
    "\n",
    "        # opens waterrights webpage by win   \n",
    "        for i in range(winbegin,winend):\n",
    "            try:\n",
    "                htmlplace = 'http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=' + str(prefix) + 'view&SYSTEM_ID='+str(i)\n",
    "                soup = make_soup(htmlplace).get_text()\n",
    "                if \"ERROR: Use UNITS undefined\" in soup or len(soup) < 1000:\n",
    "                    pass\n",
    "                else:\n",
    "                    systemnm.append(str(i))\n",
    "                    g = path + str(prefix) + str(i).zfill(6) + '.txt'\n",
    "                    b = open(g, 'w')\n",
    "                    b.write(soup.encode('utf-8').strip())   \n",
    "                    b.close()\n",
    "            except TypeError:        \n",
    "                pass\n",
    "\n",
    "        winbegin = winend\n",
    "        winend = winbegin + space\n",
    "    print(\"Scanned %s to %s\"%(prefix,winfinish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "systems = ['Pws','Ind','Mgt']\n",
    "\n",
    "for i in systems:\n",
    "    systemscraper(0,3000,1000,i,syspath)\n",
    "    systemscraper(10000,13000,1000,i,syspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code searches through text captures of Water Rights html well files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = wellpath + '*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raises(exception_types, func, *args, **kw):\n",
    "    try:\n",
    "        func(*args, **kw)\n",
    "    except exception_types:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tparser(blurb):\n",
    "    '''\n",
    "    parses a snippet of text from gettext by removing and replaces extra spaces and return characters\n",
    "    '''\n",
    "    blurb = re.sub('\\r\\n      +', '\\n',str(blurb))\n",
    "    blurb = re.sub('\\r\\n +','\\r\\n',blurb)\n",
    "    blurb = re.sub(',',';',blurb)\n",
    "    blurb = re.sub(' +',',',blurb)\n",
    "    blurb = re.sub('\\r\\n','\\n',blurb)\n",
    "    blurb = re.sub('\\n\\n','\\n',blurb)\n",
    "    return blurb\n",
    "\n",
    "def gettext(strttext,endtext,snip):\n",
    "    '''\n",
    "    selects a subset of text by searching the text for a beginning string and an ending string\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    strttext = string to find that begins text subset\n",
    "    endtext = string to find that ends the text subset\n",
    "    snip = text to subset\n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    b = subset of text; returns np.nan if no strttext is found\n",
    "    '''\n",
    "    \n",
    "    b = snip[snip.find(strttext)+len(strttext):snip.find(endtext,snip.find(strttext))].strip()\n",
    "    if snip.find(strttext) == -1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Level Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "wl = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    wellcon = gettext(' WATER LEVEL DATA:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if raises(ValueError, int, rv[j][0:21].strip(' ')[0:2])==False:\n",
    "                    rv[j] = win + ',' + rv[j][0:21] + ',' + rv[j][30:38].replace(',',';').strip(' ') + ',' + rv[j][38:].strip(' ')\n",
    "                \n",
    "                    rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                else:\n",
    "                    pass\n",
    "            wl.append('\\n'.join(rr))\n",
    "\n",
    "levs = '\\n'.join(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waterlevels = pd.read_csv(StringIO(levs),names=['WIN','Date','Level','Method'],parse_dates=['Date'])\n",
    "waterlevels.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "br = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    wellcon = gettext(' BOREHOLE INFORMATION:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if raises(ValueError, int, rv[j][0:21].strip(' ')[0:2])==False:\n",
    "                    rv[j] = win + ',' + rv[j][0:17] + ',' + rv[j][17:23] + ',' + rv[j][23:29]+ ',' + rv[j][29:58]+ ',' + rv[j][58:]\n",
    "                \n",
    "                    rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                    #print(rv[j])\n",
    "                else:\n",
    "                    pass\n",
    "            br.append('\\n'.join(rr))\n",
    "   \n",
    "bore = '\\n'.join(br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "borehole = pd.read_csv(StringIO(bore),names=['WIN','From_ft','To_ft','Diameter','Method','Fluid'])\n",
    "borehole.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling Activity Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "\n",
    "rr = []\n",
    "for f in glob.glob(filepath):\n",
    "    \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    wellcon = gettext(' DRILLER ACTIVITIES:','\\r\\n\\r\\n',text)\n",
    "    \n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            \n",
    "            act1 = str(gettext('ACTIVITY # 1 ','\\r\\n\\r\\n',wellcon))\n",
    "            actnm1 = str(gettext('ACTIVITY # 1 ','\\r\\n',wellcon)).strip(' ')\n",
    "            drllr1 = str(gettext('DRILLER: ','LICENSE #:',act1)).replace(',',' ').strip(' ')\n",
    "            lic1 =  str(gettext('LICENSE #:','\\r\\n',act1)).strip(' ')\n",
    "            strt1 = str(gettext('START DATE: ','COMPLETION DATE: ',act1)).strip(' ')\n",
    "            comp1 = str(gettext('COMPLETION DATE: ','\\r\\n',act1)).strip(' ')\n",
    "            rr.append(win+','+actnm1+','+drllr1+','+lic1+','+strt1+','+comp1)\n",
    "            #print win+','+actnm1+','+drllr1+','+lic1+','+strt1+','+comp1\n",
    "            if 'ACTIVITY # 2' in wellcon: \n",
    "                act2 = str(gettext('ACTIVITY # 2 ','\\r\\n\\r\\n',wellcon))\n",
    "                actnm2 = str(gettext('ACTIVITY # 2 ','\\r\\n',wellcon)).strip(' ')\n",
    "                drllr2 = str(gettext('DRILLER: ','LICENSE #:',act2)).replace(',',' ').strip(' ')\n",
    "                lic2 =  str(gettext('LICENSE #:','\\r\\n',act2)).strip(' ')\n",
    "                strt2 = str(gettext('START DATE: ','COMPLETION DATE: ',act2)).strip(' ')\n",
    "                comp2 = str(gettext('COMPLETION DATE: ','\\r\\n',act2)).strip(' ')\n",
    "                rr.append(win+','+actnm2+','+drllr2+','+lic2+','+strt2+','+comp2)\n",
    "    \n",
    "            if 'ACTIVITY # 3' in wellcon:\n",
    "                act3 = str(gettext('ACTIVITY # 3 ','\\r\\n\\r\\n',wellcon))\n",
    "                actnm3 = str(gettext('ACTIVITY # 3 ','\\r\\n',wellcon)).strip(' ')\n",
    "                drllr3 = str(gettext('DRILLER: ','LICENSE #:',act3)).replace(',',' ').strip(' ')\n",
    "                lic3 =  str(gettext('LICENSE #:','\\r\\n',act3)).strip(' ')\n",
    "                strt3 = str(gettext('START DATE: ','COMPLETION DATE: ',act3)).strip(' ')\n",
    "                comp3 = str(gettext('COMPLETION DATE: ','\\r\\n',act3)).strip(' ')\n",
    "                rr.append(win+','+actnm3+','+drllr3+','+lic3+','+strt3+','+comp3)\n",
    "drill = '\\n'.join(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driller = pd.read_csv(StringIO(drill),names=['WIN','activity','driller','license','start','completion'],index_col=False)#,parse_dates=['start','completion'])\n",
    "driller.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lithology Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "lit = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    litho = gettext(' LITHOLOGY:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if litho is not np.nan:\n",
    "        if len(litho) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = litho.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if j == len(rv):\n",
    "                    rv[j] = win + ',' + rv[j][0:7] + ',' + rv[j][7:13].strip(' ') + ',' + rv[j][13:95].replace(',',';').strip(' ') + ',' + rv[j][95:108].strip(' ') +','+rv[j][108:].strip(' ').replace(',',';').replace('  ',' ') + ','\n",
    "                else:\n",
    "                    if len(rv[j][0:8].strip(' ')) < 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        rv[j] = win + ',' + rv[j][0:7] + ',' + rv[j][7:13].strip(' ') + ',' + rv[j][13:95].replace(',',';').strip(' ') + ',' + rv[j][95:108].strip(' ') +','+rv[j][108:].strip(' ').replace(',',';').replace('  ',' ') + ','\n",
    "                        try:\n",
    "                            if len(rv[j+1][0:8].strip(' ')) < 1:\n",
    "                                if len(rv[j+1].replace('  ',' ').strip(' '))<350:\n",
    "                                    rv[j] = rv[j] + rv[j+1].replace(',',';').replace('  ',' ').strip(' ')\n",
    "                                else:\n",
    "                                    rv[j] = rv[j] + rv[j+1].replace(',',';').replace('  ',' ').strip(' ')[0:350]\n",
    "                        except(IndexError):\n",
    "                            pass\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            lit.append('\\n'.join(rr))\n",
    "\n",
    "                \n",
    "   \n",
    "lith = '\\n'.join(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lithlog = pd.read_csv(StringIO(lith),names=['WIN','From_ft','To_ft','Material','Color','Rock Type','Comment'])\n",
    "lithlog.drop_duplicates(inplace=True)\n",
    "lithlog.From_ft = pd.to_numeric(lithlog.From_ft, errors='coerce')\n",
    "lithlog.To_ft = pd.to_numeric(lithlog.To_ft, errors='coerce')\n",
    "lithlog.dropna(subset=['From_ft','To_ft'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lithsort(lith, x):      \n",
    "    if str(lith).lower() in str(x).lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def lithsorth(lith, x):\n",
    "    if 'other' in str(x[0]).lower():\n",
    "        b = str(x[0]).lower() + ' ' + str(x[1]).upper()\n",
    "    else:\n",
    "        b = x[0]\n",
    "    if str(lith).lower() in str(b).lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    \n",
    "lithlog['low_perm'] = lithlog['Material'].apply(lambda x: lithsort('LOW-PERMEABILITY', x),1)\n",
    "lithlog['high_perm'] = lithlog['Material'].apply(lambda x: lithsort('HIGH-PERMEABILITY', x),1)\n",
    "lithlog['clay'] = lithlog['Material'].apply(lambda x: lithsort('clay', x),1)\n",
    "lithlog['silt'] = lithlog['Material'].apply(lambda x: lithsort('silt', x),1)\n",
    "lithlog['sand'] = lithlog['Material'].apply(lambda x: lithsort('sand', x),1)\n",
    "lithlog['gravel'] = lithlog['Material'].apply(lambda x: lithsort('gravel', x),1)\n",
    "lithlog['cobbles'] = lithlog['Material'].apply(lambda x: lithsort('cobbles', x),1)\n",
    "lithlog['boulders'] = lithlog['Material'].apply(lambda x: lithsort('boulders', x),1)\n",
    "lithlog['hardpan'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('hardpan', x),1)\n",
    "lithlog['conglomerate'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('conglomerate', x),1)\n",
    "lithlog['bedrock'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('bedrock', x),1)\n",
    "lithlog['other'] = lithlog['Material'].apply(lambda x: lithsort('other', x),1)\n",
    "lithlog['water_bearing'] = lithlog['Material'].apply(lambda x: lithsort('water-bearing', x),1)\n",
    "\n",
    "\n",
    "def unitassign(x):\n",
    "    clay = x[0]\n",
    "    silt = x[1]\n",
    "    sand = x[2]\n",
    "    gravel = x[3]\n",
    "    cobbles = x[4]\n",
    "    boulders = x[5]\n",
    "    hardpan = x[6]\n",
    "    conglomerate = x[7]\n",
    "    bedrock = x[8]\n",
    "    other = x[9]\n",
    "    unitlist = [clay,silt,sand,gravel,cobbles,boulders, hardpan,conglomerate,bedrock,other]\n",
    "    unitindex = ['clay','silt','sand','gravel','cobbles','boulders', 'hardpan','conglomerate','bedrock','other']\n",
    "    unitsum = np.sum(unitlist)\n",
    "    j =str(\"\")\n",
    "    for i in range(len(unitlist)):\n",
    "        if unitlist[i] == 1:\n",
    "            if len(j)==0:\n",
    "                j = unitindex[i]\n",
    "            else:\n",
    "                j = j + \"-\" + unitindex[i]\n",
    "    return j    \n",
    "\n",
    "lithlog.units = lithlog[['clay','silt','sand','gravel','cobbles','boulders', 'hardpan','conglomerate','bedrock','other']].apply(lambda x: unitassign(x),1)\n",
    "\n",
    "consdict = {'other':'other', 'boulders':'gravel', 'gravel':'gravel', 'sand-gravel-cobbles':'sand-gravel',\n",
    "            'sand-gravel-cobbles-boulders':'sand-gravel', 'clay-boulders':'clay-gravel', \n",
    "            'clay-gravel-boulders':'clay-gravel', 'gravel-conglomerate':'conglomerate', 'cobbles':'gravel',\n",
    "            'gravel-cobbles':'gravel', 'gravel-boulders':'gravel', 'clay-gravel-cobbles-boulders':'clay-gravel', \n",
    "            'gravel-cobbles-boulders':'gravel', 'clay-cobbles-boulders':'clay-gravel', \n",
    "            'clay-cobbles':'clay-gravel','clay-sand-gravel-cobbles':'clay-gravel', \n",
    "            'clay-hardpan':'hardpan', 'cobbles-boulders':'gravel', 'clay-gravel-cobbles':'clay-gravel', \n",
    "            'clay-conglomerate':'conglomerate', 'clay-silt-sand-gravel-conglomerate':'conglomerate', \n",
    "            'sand-gravel-boulders':'sand-gravel','sand-boulders':'sand-gravel','clay-silt-gravel':'clay-gravel',\n",
    "           'clay-silt-sand':'clay-sand','clay-silt':'clay-sand','clay-sand-gravel':'clay-gravel',\n",
    "           'silt-sand':'sand','clay-silt-gravel-cobbles':'clay-gravel','silt-sand-gravel':'sand-gravel'}\n",
    "\n",
    "lithlog['unitssimp'] = lithlog.units.apply(lambda x:consdict.get(x,x),1)\n",
    "\n",
    "\n",
    "def otherassign(x):\n",
    "    if x[0] == 'other' or x[0]=='':\n",
    "        if str(x[1]).lower().find('soil') >-1:\n",
    "            return 'soil'\n",
    "        elif str(x[1]).lower().find('overburden') >-1:\n",
    "            return 'soil'\n",
    "        elif str(x[1]).lower().find('limestone') >-1:\n",
    "            return 'limestone'\n",
    "        elif str(x[1]).lower().find('shale') >-1:\n",
    "            return 'shale'\n",
    "        elif str(x[1]).lower().find('cemented') >-1:\n",
    "            return 'conglomerate'\n",
    "        elif str(x[1]).lower().find('conglomerate') >-1:\n",
    "            return 'conglomerate'\n",
    "        else:\n",
    "            return ''\n",
    "    elif x[0] == 'bedrock':\n",
    "        if str(x[1]).lower().find('limestone') >-1:\n",
    "            return 'limestone'\n",
    "        elif str(x[1]).lower().find('shale') >-1:\n",
    "            return 'shale'\n",
    "        elif str(x[1]).lower().find('cemented') >-1:\n",
    "            return 'conglomerate'\n",
    "        elif str(x[1]).lower().find('conglomerate') >-1:\n",
    "            return 'conglomerate'\n",
    "        else:\n",
    "            return 'bedrock'\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "lithlog['unitssimp'] = lithlog[['unitssimp','Comment']].apply(lambda x:otherassign(x),1)\n",
    "\n",
    "unitnumber = {'soil':0, 'sand-gravel':1, 'clay':2, 'gravel':1, 'sand':4, 'clay-gravel':5,\n",
    "              'clay-sand':3, 'conglomerate':7, 'hardpan':2, 'bedrock':6, 'limestone':6,\n",
    "              'sand-gravel-other':1, 'clay-silt-sand-gravel':3, 'clay-silt-other':2,\n",
    "              'silt':2, 'clay-other':2, 'shale':2}\n",
    "lithlog['unitnumber'] = lithlog['unitssimp'].apply(lambda x: unitnumber.get(x,8),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "const = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "\n",
    "    rev = []\n",
    "\n",
    "    wellcon = gettext('CASING:','\\r\\n\\r\\n',text)\n",
    "\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           From                    To                                          Material                                    Gage                        Diam                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:20].replace('+','-') + ',' + rv[j][20:24].strip(' ') + ',' + rv[j][24:45].replace(',',';').strip(' ') + ',' + rv[j][45:57].strip(' ') +','+rv[j][57:].strip(' ').replace('  ',' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            const.append('\\n'.join(rr))\n",
    "\n",
    "\n",
    "\n",
    "constList = '\\n'.join(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "construction = pd.read_csv(StringIO(constList),names=['WIN','From_ft','To_ft','Material','Gage_in','Diameter_in'])\n",
    "construction.drop_duplicates(inplace=True)\n",
    "construction.From_ft = pd.to_numeric(construction.From_ft,errors='coerce')\n",
    "construction.To_ft = pd.to_numeric(construction.To_ft,errors='coerce')\n",
    "construction.Diameter_in = pd.to_numeric(construction.Diameter_in,errors='coerce')\n",
    "construction.dropna(subset=['WIN','From_ft','To_ft'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screen Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "srn = []\n",
    "for f in glob.glob(filepath):    \n",
    "    text = open(f).read()   \n",
    "\n",
    "    scrntxt = gettext('SCREENS/PERFORATIONS:','\\r\\n\\r\\n',text)\n",
    "    \n",
    "    if scrntxt is not np.nan:\n",
    "        if len(scrntxt) > 10:    \n",
    "\n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = scrntxt.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           From                    To                                          Type                                                Slot                        Diam                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:18].replace('+','-') + ',' + rv[j][18:25].strip(' ') + ',' + rv[j][25:53].replace(',',';').strip(' ') + ',' + rv[j][53:69].strip(' ') +','+ rv[j][69:97].strip(' ').replace('  ',' ') +','+ rv[j][97:].replace(',',';').strip(' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            srn.append('\\n'.join(rr))\n",
    "            \n",
    "scrrn = '\\n'.join(srn)\n",
    "\n",
    "screendf = pd.read_csv(StringIO(scrrn),names=['WIN','From_ft','To_ft','Screen Type',\n",
    "                                    'Slot_Size_in','Scrn_Diam_in','Perfs'])\n",
    "screendf.drop_duplicates(inplace=True)\n",
    "\n",
    "screendf.From_ft = pd.to_numeric(screendf.From_ft,errors='coerce')\n",
    "screendf.To_ft = pd.to_numeric(screendf.To_ft,errors='coerce')\n",
    "\n",
    "scrnInt = screendf.groupby('WIN').agg({'From_ft':np.min, 'To_ft':np.min})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrnInt.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pumping Test Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "pmp = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    welltest = gettext('WELL TESTS:','\\r\\n\\r\\n\\r\\n ',text)\n",
    "    #print wellcon\n",
    "    if welltest is not np.nan:\n",
    "        if len(welltest) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = welltest.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           DATE                    Test Method                                  Yield                                    Drawdown                        Time pump                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:22] + ',' + rv[j][22:41].replace(',',';').strip(' ') + ',' + rv[j][41:54].strip(' ') + ',' + rv[j][54:70].strip(' ') +','+rv[j][70:].strip(' ').replace('  ',' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            pmp.append('\\n'.join(rr))\n",
    "\n",
    "                \n",
    "   \n",
    "pump = '\\n'.join(pmp)\n",
    "\n",
    "pumpingtests = pd.read_csv(StringIO(pump), names=['WIN', 'Date', 'Method', 'Yield_cfs', \n",
    "                                                  'Drawdown_ft', 'Pump_Dur_hr'])#,parse_dates=['Date'])\n",
    "pumpingtests.drop_duplicates(inplace=True)\n",
    "pumpingtests['Yield_cfs'] = pd.to_numeric(pumpingtests.Yield_cfs, errors='coerce')\n",
    "pumpingtests['Drawdown_ft'] = pd.to_numeric(pumpingtests.Drawdown_ft, errors='coerce')\n",
    "pumpingtests['Pump_Dur_hr'] = pd.to_numeric(pumpingtests.Pump_Dur_hr, errors='coerce')\n",
    "pumpingtests.dropna(subset=['Yield_cfs','Drawdown_ft','Pump_Dur_hr'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pumpT = pd.merge(pumpingtests, construction, on='WIN',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTrans(x,S):\n",
    "    Q = float(x[0])*86400.0\n",
    "    d = float(x[1])\n",
    "    t = float(x[2])/24.0\n",
    "    if d == 0:\n",
    "        sc = Q/0.1\n",
    "    else:\n",
    "        sc = Q/d\n",
    "        \n",
    "    r = float(x[3])/24.0\n",
    "    if r == 0:\n",
    "        return np.nan\n",
    "\n",
    "    else:\n",
    "        T0 = 100.0\n",
    "        delt = 100.0\n",
    "        while abs(delt) > 0.01:\n",
    "            T = (sc/(4*np.pi))*(np.log((2.25*T0*t)/(r*r*S)))\n",
    "            delt = T - T0\n",
    "            T0 = T\n",
    "        return T\n",
    "             \n",
    "S = 0.0002\n",
    "\n",
    "pumpT['trans'] = pumpT[['Yield_cfs','Drawdown_ft','Pump_Dur_hr','Diameter_in']].apply(lambda x: getTrans(x,S),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pumpT.drop(['From_ft','To_ft','Material','Gage_in'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellTrans = pd.merge(pumpT, scrnInt, on='WIN', how='left')\n",
    "wellTrans.dropna(subset=['trans'],inplace=True)\n",
    "wellTrans = wellTrans[(wellTrans.Drawdown_ft > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System and Source Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathname = 'D:/PROJECTS/WR_DATA/RawSystems/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = glob.glob(pathname +'*.txt')\n",
    "\n",
    "sourcet, conn, use = {}, {}, {}\n",
    "\n",
    "indcode, systype, sysnum, link, sysname, city, county, syscat, huc, pwsid, deqcat, numberofsources = [],[],[],[],[],[],[],[],[],[],[],[]\n",
    "source, system, systemid, pls, sourcetype, sourceuse, win, wrnum, sourcecode,sourceid = [],[],[],[],[],[],[],[],[],[]\n",
    "system_id = []\n",
    "\n",
    "for f in range(len(files)): \n",
    "    text = open(files[f]).read()\n",
    "    systemname = gettext('System  Name:','Address:',text)\n",
    "    sid = gettext('Public Water System ID:','DEQ',text)\n",
    "    srcind = [m.start() for m in re.finditer('Source Summary', text)]\n",
    "    \n",
    "    prefix = os.path.split(files[f])[1][0:3]\n",
    "    html = 'http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo='+ prefix +'view&SYSTEM_ID='\n",
    "    \n",
    "    sysnum.append(int(os.path.split(files[f])[1][3:9]))\n",
    "    linknum = int(os.path.split(files[f])[1][3:9])\n",
    "    systype.append(prefix)\n",
    "    link.append(html+str(linknum))\n",
    "    \n",
    "    systid = prefix+'-'+str(linknum).zfill(5)\n",
    "    \n",
    "    system_id.append(systid)\n",
    "    sysname.append(gettext('System  Name:','Address:',text))\n",
    "    city.append(gettext('City:','State:',text))\n",
    "    county.append(gettext('County:','Primary Use:',text))\n",
    "    syscat.append(gettext('Primary Use:','Standard',text))\n",
    "    huc.append(gettext('Hydro Unit Code:','Public',text))\n",
    "    pwsid.append(gettext('Public Water System ID:','DEQ',text))\n",
    "    deqcat.append(gettext('DEQ System Category:','\\n',text))\n",
    "    indcode.append(gettext('Standard Industrial Code:','Dual',text))\n",
    "    \n",
    "    numberofsources.append(len(srcind))\n",
    "    \n",
    "    for i in range(len(srcind)):\n",
    "\n",
    "        if i == len(srcind)-1:\n",
    "            subtext = text[srcind[i]:-1]\n",
    "        else:\n",
    "            subtext = text[srcind[i]:srcind[i+1]]\n",
    "            \n",
    "        source.append(gettext('Source Name:','\\n',subtext))\n",
    "        pls.append(gettext('PLS Location:','\\n',subtext))\n",
    "        sourcetype.append(gettext('Source Type:','\\n',subtext))\n",
    "        sourceuse.append(gettext('Primary Use:','\\n',subtext))\n",
    "        win.append(gettext('Well ID Number:','(C',subtext))\n",
    "        sourcecode.append(gettext('DEHN Source Code:','\\n',subtext))\n",
    "        wrnum.append(gettext('Water Right Numbers:','\\n',subtext))\n",
    "        system.append(systemname)\n",
    "        systemid.append(sid)\n",
    "        srcid = systid +'-'+str(i).zfill(2)\n",
    "        sourceid.append(srcid)\n",
    "        \n",
    "        table = gettext(' Source Record (ACFT)\\r\\n','\\r\\n \\r',subtext)\n",
    "        table = re.sub('Master +Meter','MasterMeter',str(table))\n",
    "        table = re.sub('Master +Met','MasterMeter',table)\n",
    "        table = re.sub('Individual +Meters','IndividualMeters',table)\n",
    "        table = re.sub('Measuring +Method','MeasuringMethod',table)\n",
    "        table = tparser(table) \n",
    "        rv = table.split('\\n')\n",
    "        b = []\n",
    "        for j in range(len(rv)):    \n",
    "            if rv[j].count(',') > 15:\n",
    "                rb = rv[j].split(',')\n",
    "                rb.insert(15,'\\n')\n",
    "                b.append(','.join(rb))\n",
    "            elif rv[j].count(',')==15:\n",
    "                b.append(rv[j])  \n",
    "            elif rv[j].count(',') < 15 and rv[j].count(',') > 4:\n",
    "                b.append(rv[j] + ','*(15-rv[j].count(',')))\n",
    "            else:\n",
    "                pass\n",
    "        rev = '\\n'.join(b)\n",
    "        try:\n",
    "            sourcet[srcid] = pd.read_csv(StringIO(rev))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    usetable = gettext(' Annual Use Info (Acft) \\r\\n','\\r\\n \\r',text)\n",
    "    usetable = tparser(usetable)\n",
    "    try:\n",
    "        use[systid] = pd.read_csv(StringIO(usetable))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    conntable = gettext(' Annual Connection Info\\r\\n','\\r\\n\\r\\n ',text)\n",
    "    conntable = tparser(conntable)\n",
    "    try:\n",
    "        conn[systid] = pd.read_csv(StringIO(conntable))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sysdict = {'systype':systype, 'systemnum': sysnum, 'link':link, 'sysname':sysname, 'city':city, \n",
    "           'county':county, 'syscat':syscat, 'indust code':indcode, 'number of sources':numberofsources,\n",
    "          'huc':huc, 'pwsid':pwsid,'deqcat':deqcat, 'systemid':system_id}\n",
    "\n",
    "systems = pd.DataFrame(sysdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourcedict = {'source':source, 'system id': systemid, 'system':system, 'pls':pls, 'source type': sourcetype,\n",
    "          'source use':sourceuse, 'win':win, 'wrnum':wrnum, 'DEHN source id':sourcecode, 'source id':sourceid}\n",
    "\n",
    "sources = pd.DataFrame(sourcedict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sourcetake = pd.concat(sourcet)\n",
    "sourcetake.reset_index(inplace=True)\n",
    "sourcetake.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "sourcetake.set_index(['systemid','Year'],inplace=True)\n",
    "sourcetake.drop(['level_1','Measuring','MeasuringMethod','Unnamed: 15','Mea','Meth','Ann'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srctake = sourcetake.stack().to_frame()\n",
    "srctake.rename(columns={'0':'Use (ac-ft)'},inplace=True)\n",
    "srctake.reset_index(inplace=True)\n",
    "srctake['Year'] = pd.to_numeric(srctake['Year'],errors='coerce')\n",
    "srctake = srctake[(srctake['Year']<=datetime.today().year)&(srctake['Year']>=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srctake = srctake[srctake['level_2'].isin(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])]\n",
    "srctake['my'] = srctake[['Year','level_2']].apply(lambda x: pd.to_datetime(str(int(x[0]))+' '+str(x[1]), format='%Y %b'),1)\n",
    "srctake.columns = ['sourceid','Year','Month','Use','datetime']\n",
    "srctake['systemid'] = srctake['sourceid'].apply(lambda x: str(x)[0:9],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuse = pd.concat(use)\n",
    "systemuse.reset_index(inplace=True)\n",
    "systemuse.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "systemuse.drop(['level_1','Tota','nan'],axis=1,inplace=True)\n",
    "cols = ['Commercial','Domestic','Industrial','Institutnl','Other','Stock','Unmetered','Wholesale']\n",
    "for col in cols:\n",
    "    systemuse[col] = pd.to_numeric(systemuse[col], errors='coerce')\n",
    "systemuse['Total'] = pd.to_numeric(systemuse['Total'])\n",
    "systemuse['Total1'] = systemuse[cols].sum(axis=1)\n",
    "systemuse['Year'] = pd.to_numeric(systemuse['Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "systemuseData = systemuse[systemuse['Year']<2017]\n",
    "systemuseData = systemuse[systemuse.Total < 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append Existing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.waterrights.utah.gov/cgi-bin/pubdump.exe?DBNAME=WELLDB&SECURITYKEY=wrt2012access<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/pubdump.exe?DBNAME=WRDB&SECURITYKEY=wrt2012access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>win</th>\n",
       "      <th>activityType</th>\n",
       "      <th>SC_REC_DATE</th>\n",
       "      <th>SC_BEG_DATE</th>\n",
       "      <th>AC_REC_DATE</th>\n",
       "      <th>AC_COM_DATE</th>\n",
       "      <th>LOG_REC_DATE</th>\n",
       "      <th>ACTIV_START_DATE</th>\n",
       "      <th>ACTIV_COM_DATE</th>\n",
       "      <th>LOG_COMPLETE</th>\n",
       "      <th>driller_Number</th>\n",
       "      <th>REQUEST_DATE</th>\n",
       "      <th>AUTHOR_DATE</th>\n",
       "      <th>scannedWellLog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150534</td>\n",
       "      <td>437994</td>\n",
       "      <td>New</td>\n",
       "      <td>20140920</td>\n",
       "      <td>20140921</td>\n",
       "      <td>20141008</td>\n",
       "      <td>20140927</td>\n",
       "      <td>20141027</td>\n",
       "      <td>20140921</td>\n",
       "      <td>20140927</td>\n",
       "      <td></td>\n",
       "      <td>711</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>150542</td>\n",
       "      <td>437999</td>\n",
       "      <td>New</td>\n",
       "      <td>20140923</td>\n",
       "      <td>20140923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141008</td>\n",
       "      <td>20140923</td>\n",
       "      <td>20141006</td>\n",
       "      <td></td>\n",
       "      <td>808</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150543</td>\n",
       "      <td>438000</td>\n",
       "      <td>New</td>\n",
       "      <td>20140923</td>\n",
       "      <td>20140925</td>\n",
       "      <td>20141103</td>\n",
       "      <td>20141001</td>\n",
       "      <td>20141023</td>\n",
       "      <td>20140927</td>\n",
       "      <td>20141001</td>\n",
       "      <td></td>\n",
       "      <td>527</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>150544</td>\n",
       "      <td>438001</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20140923</td>\n",
       "      <td>20149242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141103</td>\n",
       "      <td>20140923</td>\n",
       "      <td>20141020</td>\n",
       "      <td></td>\n",
       "      <td>593</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150545</td>\n",
       "      <td>438002</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20140923</td>\n",
       "      <td>20149242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141003</td>\n",
       "      <td>20141022</td>\n",
       "      <td>20141022</td>\n",
       "      <td></td>\n",
       "      <td>593</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>150547</td>\n",
       "      <td>438004</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20140924</td>\n",
       "      <td>20140925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141008</td>\n",
       "      <td>20141001</td>\n",
       "      <td>20141001</td>\n",
       "      <td></td>\n",
       "      <td>695</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150551</td>\n",
       "      <td>438007</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20140925</td>\n",
       "      <td>20140925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>742</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>150559</td>\n",
       "      <td>438014</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20140926</td>\n",
       "      <td>20140930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141107</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>728</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150560</td>\n",
       "      <td>438015</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20140926</td>\n",
       "      <td>20140930</td>\n",
       "      <td>20141118</td>\n",
       "      <td>20141008</td>\n",
       "      <td>20141107</td>\n",
       "      <td>20140926</td>\n",
       "      <td>20141008</td>\n",
       "      <td></td>\n",
       "      <td>728</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>150561</td>\n",
       "      <td>437440</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20140924</td>\n",
       "      <td>20140924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20140929</td>\n",
       "      <td>20140924</td>\n",
       "      <td>20140924</td>\n",
       "      <td></td>\n",
       "      <td>868</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>150562</td>\n",
       "      <td>10519</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20140927</td>\n",
       "      <td>20140927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20140929</td>\n",
       "      <td>20140927</td>\n",
       "      <td>20140927</td>\n",
       "      <td></td>\n",
       "      <td>868</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>150563</td>\n",
       "      <td>24617</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20140929</td>\n",
       "      <td>20140929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141205</td>\n",
       "      <td>20141112</td>\n",
       "      <td>20141112</td>\n",
       "      <td></td>\n",
       "      <td>495</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>150564</td>\n",
       "      <td>438016</td>\n",
       "      <td>New</td>\n",
       "      <td>20140929</td>\n",
       "      <td>20140929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141028</td>\n",
       "      <td>20140929</td>\n",
       "      <td>20141015</td>\n",
       "      <td></td>\n",
       "      <td>495</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>150565</td>\n",
       "      <td>438017</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20140930</td>\n",
       "      <td>20140930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141006</td>\n",
       "      <td>20141001</td>\n",
       "      <td>20141001</td>\n",
       "      <td></td>\n",
       "      <td>575</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>150567</td>\n",
       "      <td>33592</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20140925</td>\n",
       "      <td>20140925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20140930</td>\n",
       "      <td>20140925</td>\n",
       "      <td>20140926</td>\n",
       "      <td></td>\n",
       "      <td>572</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>150568</td>\n",
       "      <td>438019</td>\n",
       "      <td>New</td>\n",
       "      <td>20140930</td>\n",
       "      <td>20140923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141124</td>\n",
       "      <td>20140922</td>\n",
       "      <td>20140926</td>\n",
       "      <td></td>\n",
       "      <td>878</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>150570</td>\n",
       "      <td>438021</td>\n",
       "      <td>New</td>\n",
       "      <td>20141001</td>\n",
       "      <td>20141001</td>\n",
       "      <td>20150824</td>\n",
       "      <td>20150819</td>\n",
       "      <td>20141023</td>\n",
       "      <td>20141001</td>\n",
       "      <td>20141002</td>\n",
       "      <td></td>\n",
       "      <td>346</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>150571</td>\n",
       "      <td>438022</td>\n",
       "      <td>New</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td></td>\n",
       "      <td>523</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>150572</td>\n",
       "      <td>438023</td>\n",
       "      <td>New</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td></td>\n",
       "      <td>523</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>150573</td>\n",
       "      <td>438024</td>\n",
       "      <td>New</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td></td>\n",
       "      <td>523</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>150574</td>\n",
       "      <td>438025</td>\n",
       "      <td>New</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td></td>\n",
       "      <td>523</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>150575</td>\n",
       "      <td>438026</td>\n",
       "      <td>New</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19910518</td>\n",
       "      <td>19910518</td>\n",
       "      <td></td>\n",
       "      <td>523</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>150577</td>\n",
       "      <td>438028</td>\n",
       "      <td>New</td>\n",
       "      <td>20141002</td>\n",
       "      <td>20141002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141031</td>\n",
       "      <td>20141002</td>\n",
       "      <td>20141008</td>\n",
       "      <td></td>\n",
       "      <td>240</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>150578</td>\n",
       "      <td>438029</td>\n",
       "      <td>New</td>\n",
       "      <td>20141002</td>\n",
       "      <td>20141002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141031</td>\n",
       "      <td>20141009</td>\n",
       "      <td>20141023</td>\n",
       "      <td></td>\n",
       "      <td>240</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>151571</td>\n",
       "      <td>428819</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20141003</td>\n",
       "      <td>20141006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141029</td>\n",
       "      <td>20141017</td>\n",
       "      <td>20141017</td>\n",
       "      <td></td>\n",
       "      <td>492</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>151572</td>\n",
       "      <td>438030</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20141003</td>\n",
       "      <td>20141006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141029</td>\n",
       "      <td>20141008</td>\n",
       "      <td>20141017</td>\n",
       "      <td></td>\n",
       "      <td>492</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>151577</td>\n",
       "      <td>438035</td>\n",
       "      <td>New</td>\n",
       "      <td>20141007</td>\n",
       "      <td>20141007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141211</td>\n",
       "      <td>20141007</td>\n",
       "      <td>20141205</td>\n",
       "      <td></td>\n",
       "      <td>524</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>151579</td>\n",
       "      <td>429917</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20141002</td>\n",
       "      <td>20141002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141007</td>\n",
       "      <td>20141002</td>\n",
       "      <td>20141002</td>\n",
       "      <td></td>\n",
       "      <td>863</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>151580</td>\n",
       "      <td>438037</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20141006</td>\n",
       "      <td>20141006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20141007</td>\n",
       "      <td>20141007</td>\n",
       "      <td>20141007</td>\n",
       "      <td></td>\n",
       "      <td>778</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>151589</td>\n",
       "      <td>438046</td>\n",
       "      <td>New</td>\n",
       "      <td>20141008</td>\n",
       "      <td>20141014</td>\n",
       "      <td>20141103</td>\n",
       "      <td>20141021</td>\n",
       "      <td>20141105</td>\n",
       "      <td>20141014</td>\n",
       "      <td>20141020</td>\n",
       "      <td></td>\n",
       "      <td>626</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52421</th>\n",
       "      <td>157015</td>\n",
       "      <td>2990</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20160711</td>\n",
       "      <td>20160711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>715</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52422</th>\n",
       "      <td>157016</td>\n",
       "      <td>439808</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20160711</td>\n",
       "      <td>20160711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>715</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52423</th>\n",
       "      <td>157050</td>\n",
       "      <td>439815</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20151213</td>\n",
       "      <td>20151213</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160620</td>\n",
       "      <td>20151213</td>\n",
       "      <td>20151213</td>\n",
       "      <td></td>\n",
       "      <td>813</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52424</th>\n",
       "      <td>157056</td>\n",
       "      <td>434018</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20160514</td>\n",
       "      <td>20160514</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160620</td>\n",
       "      <td>20160514</td>\n",
       "      <td>20160514</td>\n",
       "      <td></td>\n",
       "      <td>813</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52425</th>\n",
       "      <td>157064</td>\n",
       "      <td>438759</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20151125</td>\n",
       "      <td>20151125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160613</td>\n",
       "      <td>20151125</td>\n",
       "      <td>20151125</td>\n",
       "      <td></td>\n",
       "      <td>527</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52426</th>\n",
       "      <td>157102</td>\n",
       "      <td>439839</td>\n",
       "      <td>New</td>\n",
       "      <td>20160719</td>\n",
       "      <td>20160721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>660</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52427</th>\n",
       "      <td>157111</td>\n",
       "      <td>439845</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20160720</td>\n",
       "      <td>20160721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>527</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52428</th>\n",
       "      <td>157112</td>\n",
       "      <td>17346</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20160720</td>\n",
       "      <td>20160721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>527</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52429</th>\n",
       "      <td>157128</td>\n",
       "      <td>438706</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20150829</td>\n",
       "      <td>20150829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160620</td>\n",
       "      <td>20160829</td>\n",
       "      <td>20150829</td>\n",
       "      <td></td>\n",
       "      <td>813</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52430</th>\n",
       "      <td>155694</td>\n",
       "      <td>439546</td>\n",
       "      <td>New</td>\n",
       "      <td>20160418</td>\n",
       "      <td>20160418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160603</td>\n",
       "      <td>20160418</td>\n",
       "      <td>30160430</td>\n",
       "      <td></td>\n",
       "      <td>527</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52431</th>\n",
       "      <td>155711</td>\n",
       "      <td>439558</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20140505</td>\n",
       "      <td>20140505</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160420</td>\n",
       "      <td>20140505</td>\n",
       "      <td>20140505</td>\n",
       "      <td></td>\n",
       "      <td>776</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52432</th>\n",
       "      <td>155728</td>\n",
       "      <td>439566</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20160419</td>\n",
       "      <td>20160419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160426</td>\n",
       "      <td>20160419</td>\n",
       "      <td>20160419</td>\n",
       "      <td></td>\n",
       "      <td>778</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52433</th>\n",
       "      <td>155758</td>\n",
       "      <td>439592</td>\n",
       "      <td>New</td>\n",
       "      <td>20160503</td>\n",
       "      <td>20160503</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160714</td>\n",
       "      <td>20160502</td>\n",
       "      <td>20160509</td>\n",
       "      <td></td>\n",
       "      <td>869</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52434</th>\n",
       "      <td>155761</td>\n",
       "      <td>439594</td>\n",
       "      <td>New</td>\n",
       "      <td>20160506</td>\n",
       "      <td>20160428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160608</td>\n",
       "      <td>20160428</td>\n",
       "      <td>20160504</td>\n",
       "      <td></td>\n",
       "      <td>728</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52435</th>\n",
       "      <td>155763</td>\n",
       "      <td>439596</td>\n",
       "      <td>New</td>\n",
       "      <td>20160504</td>\n",
       "      <td>20160504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160606</td>\n",
       "      <td>20160504</td>\n",
       "      <td>20160506</td>\n",
       "      <td></td>\n",
       "      <td>346</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52436</th>\n",
       "      <td>155773</td>\n",
       "      <td>439606</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20160509</td>\n",
       "      <td>20160510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160608</td>\n",
       "      <td>20160531</td>\n",
       "      <td>20160531</td>\n",
       "      <td></td>\n",
       "      <td>398</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52437</th>\n",
       "      <td>155774</td>\n",
       "      <td>439607</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20160509</td>\n",
       "      <td>20160510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160518</td>\n",
       "      <td>20160509</td>\n",
       "      <td>20160511</td>\n",
       "      <td></td>\n",
       "      <td>398</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52438</th>\n",
       "      <td>155788</td>\n",
       "      <td>439615</td>\n",
       "      <td>New</td>\n",
       "      <td>19850508</td>\n",
       "      <td>19850508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19850605</td>\n",
       "      <td>19850508</td>\n",
       "      <td>19850509</td>\n",
       "      <td></td>\n",
       "      <td>492</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52439</th>\n",
       "      <td>155806</td>\n",
       "      <td>439627</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20160512</td>\n",
       "      <td>20160512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>619</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52440</th>\n",
       "      <td>155807</td>\n",
       "      <td>439628</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20160512</td>\n",
       "      <td>20160516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>619</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52441</th>\n",
       "      <td>155879</td>\n",
       "      <td>439667</td>\n",
       "      <td>Deepen</td>\n",
       "      <td>20160601</td>\n",
       "      <td>20160601</td>\n",
       "      <td>20160701</td>\n",
       "      <td>20160621</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>728</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52442</th>\n",
       "      <td>156889</td>\n",
       "      <td>438436</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20160528</td>\n",
       "      <td>20160528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160603</td>\n",
       "      <td>20160528</td>\n",
       "      <td>20160528</td>\n",
       "      <td></td>\n",
       "      <td>704</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52443</th>\n",
       "      <td>156907</td>\n",
       "      <td>439707</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20160609</td>\n",
       "      <td>20160616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160617</td>\n",
       "      <td>20160614</td>\n",
       "      <td>20160614</td>\n",
       "      <td></td>\n",
       "      <td>486</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52444</th>\n",
       "      <td>156995</td>\n",
       "      <td>439789</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20160616</td>\n",
       "      <td>20160616</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160705</td>\n",
       "      <td>20160616</td>\n",
       "      <td>20160617</td>\n",
       "      <td></td>\n",
       "      <td>527</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52445</th>\n",
       "      <td>156996</td>\n",
       "      <td>439790</td>\n",
       "      <td>New</td>\n",
       "      <td>19801129</td>\n",
       "      <td>19801129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19801202</td>\n",
       "      <td>19801129</td>\n",
       "      <td>19801129</td>\n",
       "      <td></td>\n",
       "      <td>240</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52446</th>\n",
       "      <td>157020</td>\n",
       "      <td>439812</td>\n",
       "      <td>New</td>\n",
       "      <td>20160712</td>\n",
       "      <td>20160712</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>802</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52447</th>\n",
       "      <td>157040</td>\n",
       "      <td>31089</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20160620</td>\n",
       "      <td>20160620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160630</td>\n",
       "      <td>20160620</td>\n",
       "      <td>20160620</td>\n",
       "      <td></td>\n",
       "      <td>863</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52448</th>\n",
       "      <td>157057</td>\n",
       "      <td>24244</td>\n",
       "      <td>Pump Work</td>\n",
       "      <td>20160607</td>\n",
       "      <td>20160607</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20160615</td>\n",
       "      <td>20160607</td>\n",
       "      <td>20160607</td>\n",
       "      <td></td>\n",
       "      <td>881</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52449</th>\n",
       "      <td>157108</td>\n",
       "      <td>439843</td>\n",
       "      <td>Replace</td>\n",
       "      <td>20160719</td>\n",
       "      <td>20160720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>760</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52450</th>\n",
       "      <td>157109</td>\n",
       "      <td>439844</td>\n",
       "      <td>Abandon</td>\n",
       "      <td>20160719</td>\n",
       "      <td>20160720</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>760</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52451 rows  15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       recordId     win activityType SC_REC_DATE SC_BEG_DATE AC_REC_DATE  \\\n",
       "0        150534  437994          New    20140920    20140921    20141008   \n",
       "1        150542  437999          New    20140923    20140923         NaN   \n",
       "2        150543  438000          New    20140923    20140925    20141103   \n",
       "3        150544  438001      Replace    20140923    20149242         NaN   \n",
       "4        150545  438002      Abandon    20140923    20149242         NaN   \n",
       "5        150547  438004      Abandon    20140924    20140925         NaN   \n",
       "6        150551  438007      Abandon    20140925    20140925         NaN   \n",
       "7        150559  438014      Abandon    20140926    20140930         NaN   \n",
       "8        150560  438015      Replace    20140926    20140930    20141118   \n",
       "9        150561  437440    Pump Work    20140924    20140924         NaN   \n",
       "10       150562   10519    Pump Work    20140927    20140927         NaN   \n",
       "11       150563   24617      Abandon    20140929    20140929         NaN   \n",
       "12       150564  438016          New    20140929    20140929         NaN   \n",
       "13       150565  438017      Abandon    20140930    20140930         NaN   \n",
       "14       150567   33592    Pump Work    20140925    20140925         NaN   \n",
       "15       150568  438019          New    20140930    20140923         NaN   \n",
       "16       150570  438021          New    20141001    20141001    20150824   \n",
       "17       150571  438022          New    19910518    19910518         NaN   \n",
       "18       150572  438023          New    19910518    19910518         NaN   \n",
       "19       150573  438024          New    19910518    19910518         NaN   \n",
       "20       150574  438025          New    19910518    19910518         NaN   \n",
       "21       150575  438026          New    19910518    19910518         NaN   \n",
       "22       150577  438028          New    20141002    20141002         NaN   \n",
       "23       150578  438029          New    20141002    20141002         NaN   \n",
       "24       151571  428819      Abandon    20141003    20141006         NaN   \n",
       "25       151572  438030      Replace    20141003    20141006         NaN   \n",
       "26       151577  438035          New    20141007    20141007         NaN   \n",
       "27       151579  429917    Pump Work    20141002    20141002         NaN   \n",
       "28       151580  438037    Pump Work    20141006    20141006         NaN   \n",
       "29       151589  438046          New    20141008    20141014    20141103   \n",
       "...         ...     ...          ...         ...         ...         ...   \n",
       "52421    157015    2990      Abandon    20160711    20160711         NaN   \n",
       "52422    157016  439808      Replace    20160711    20160711         NaN   \n",
       "52423    157050  439815    Pump Work    20151213    20151213         NaN   \n",
       "52424    157056  434018    Pump Work    20160514    20160514         NaN   \n",
       "52425    157064  438759    Pump Work    20151125    20151125         NaN   \n",
       "52426    157102  439839          New    20160719    20160721         NaN   \n",
       "52427    157111  439845      Replace    20160720    20160721         NaN   \n",
       "52428    157112   17346      Abandon    20160720    20160721         NaN   \n",
       "52429    157128  438706    Pump Work    20150829    20150829         NaN   \n",
       "52430    155694  439546          New    20160418    20160418         NaN   \n",
       "52431    155711  439558    Pump Work    20140505    20140505         NaN   \n",
       "52432    155728  439566    Pump Work    20160419    20160419         NaN   \n",
       "52433    155758  439592          New    20160503    20160503         NaN   \n",
       "52434    155761  439594          New    20160506    20160428         NaN   \n",
       "52435    155763  439596          New    20160504    20160504         NaN   \n",
       "52436    155773  439606      Abandon    20160509    20160510         NaN   \n",
       "52437    155774  439607      Replace    20160509    20160510         NaN   \n",
       "52438    155788  439615          New    19850508    19850508         NaN   \n",
       "52439    155806  439627      Abandon    20160512    20160512         NaN   \n",
       "52440    155807  439628      Replace    20160512    20160516         NaN   \n",
       "52441    155879  439667       Deepen    20160601    20160601    20160701   \n",
       "52442    156889  438436    Pump Work    20160528    20160528         NaN   \n",
       "52443    156907  439707      Abandon    20160609    20160616         NaN   \n",
       "52444    156995  439789      Abandon    20160616    20160616         NaN   \n",
       "52445    156996  439790          New    19801129    19801129         NaN   \n",
       "52446    157020  439812          New    20160712    20160712         NaN   \n",
       "52447    157040   31089    Pump Work    20160620    20160620         NaN   \n",
       "52448    157057   24244    Pump Work    20160607    20160607         NaN   \n",
       "52449    157108  439843      Replace    20160719    20160720         NaN   \n",
       "52450    157109  439844      Abandon    20160719    20160720         NaN   \n",
       "\n",
       "      AC_COM_DATE LOG_REC_DATE ACTIV_START_DATE ACTIV_COM_DATE LOG_COMPLETE  \\\n",
       "0        20140927     20141027         20140921       20140927                \n",
       "1             NaN     20141008         20140923       20141006                \n",
       "2        20141001     20141023         20140927       20141001                \n",
       "3             NaN     20141103         20140923       20141020                \n",
       "4             NaN     20141003         20141022       20141022                \n",
       "5             NaN     20141008         20141001       20141001                \n",
       "6             NaN          NaN                             NaN                \n",
       "7             NaN     20141107                             NaN                \n",
       "8        20141008     20141107         20140926       20141008                \n",
       "9             NaN     20140929         20140924       20140924                \n",
       "10            NaN     20140929         20140927       20140927                \n",
       "11            NaN     20141205         20141112       20141112                \n",
       "12            NaN     20141028         20140929       20141015                \n",
       "13            NaN     20141006         20141001       20141001                \n",
       "14            NaN     20140930         20140925       20140926                \n",
       "15            NaN     20141124         20140922       20140926                \n",
       "16       20150819     20141023         20141001       20141002                \n",
       "17            NaN          NaN         19910518       19910518                \n",
       "18            NaN          NaN         19910518       19910518                \n",
       "19            NaN          NaN         19910518       19910518                \n",
       "20            NaN          NaN         19910518       19910518                \n",
       "21            NaN          NaN         19910518       19910518                \n",
       "22            NaN     20141031         20141002       20141008                \n",
       "23            NaN     20141031         20141009       20141023                \n",
       "24            NaN     20141029         20141017       20141017                \n",
       "25            NaN     20141029         20141008       20141017                \n",
       "26            NaN     20141211         20141007       20141205                \n",
       "27            NaN     20141007         20141002       20141002                \n",
       "28            NaN     20141007         20141007       20141007                \n",
       "29       20141021     20141105         20141014       20141020                \n",
       "...           ...          ...              ...            ...          ...   \n",
       "52421         NaN          NaN                             NaN                \n",
       "52422         NaN          NaN                             NaN                \n",
       "52423         NaN     20160620         20151213       20151213                \n",
       "52424         NaN     20160620         20160514       20160514                \n",
       "52425         NaN     20160613         20151125       20151125                \n",
       "52426         NaN          NaN                             NaN                \n",
       "52427         NaN          NaN                             NaN                \n",
       "52428         NaN          NaN                             NaN                \n",
       "52429         NaN     20160620         20160829       20150829                \n",
       "52430         NaN     20160603         20160418       30160430                \n",
       "52431         NaN     20160420         20140505       20140505                \n",
       "52432         NaN     20160426         20160419       20160419                \n",
       "52433         NaN     20160714         20160502       20160509                \n",
       "52434         NaN     20160608         20160428       20160504                \n",
       "52435         NaN     20160606         20160504       20160506                \n",
       "52436         NaN     20160608         20160531       20160531                \n",
       "52437         NaN     20160518         20160509       20160511                \n",
       "52438         NaN     19850605         19850508       19850509                \n",
       "52439         NaN          NaN                             NaN                \n",
       "52440         NaN          NaN                             NaN                \n",
       "52441    20160621          NaN                             NaN                \n",
       "52442         NaN     20160603         20160528       20160528                \n",
       "52443         NaN     20160617         20160614       20160614                \n",
       "52444         NaN     20160705         20160616       20160617                \n",
       "52445         NaN     19801202         19801129       19801129                \n",
       "52446         NaN          NaN                             NaN                \n",
       "52447         NaN     20160630         20160620       20160620                \n",
       "52448         NaN     20160615         20160607       20160607                \n",
       "52449         NaN          NaN                             NaN                \n",
       "52450         NaN          NaN                             NaN                \n",
       "\n",
       "       driller_Number REQUEST_DATE AUTHOR_DATE scannedWellLog  \n",
       "0                 711                                     NaN  \n",
       "1                 808                                     NaN  \n",
       "2                 527                                     NaN  \n",
       "3                 593                                     NaN  \n",
       "4                 593                                     NaN  \n",
       "5                 695                                     NaN  \n",
       "6                 742                                     NaN  \n",
       "7                 728                                     NaN  \n",
       "8                 728                                     NaN  \n",
       "9                 868                                     NaN  \n",
       "10                868                                     NaN  \n",
       "11                495                                     NaN  \n",
       "12                495                                     NaN  \n",
       "13                575                                     NaN  \n",
       "14                572                                     NaN  \n",
       "15                878                                     NaN  \n",
       "16                346                                     NaN  \n",
       "17                523                                     NaN  \n",
       "18                523                                     NaN  \n",
       "19                523                                     NaN  \n",
       "20                523                                     NaN  \n",
       "21                523                                     NaN  \n",
       "22                240                                     NaN  \n",
       "23                240                                     NaN  \n",
       "24                492                                     NaN  \n",
       "25                492                                     NaN  \n",
       "26                524                                     NaN  \n",
       "27                863                                     NaN  \n",
       "28                778                                     NaN  \n",
       "29                626                                     NaN  \n",
       "...               ...          ...         ...            ...  \n",
       "52421             715                                     NaN  \n",
       "52422             715                                     NaN  \n",
       "52423             813                                     NaN  \n",
       "52424             813                                     NaN  \n",
       "52425             527                                     NaN  \n",
       "52426             660                                     NaN  \n",
       "52427             527                                     NaN  \n",
       "52428             527                                     NaN  \n",
       "52429             813                                     NaN  \n",
       "52430             527                                     NaN  \n",
       "52431             776                                     NaN  \n",
       "52432             778                                     NaN  \n",
       "52433             869                                     NaN  \n",
       "52434             728                                     NaN  \n",
       "52435             346                                     NaN  \n",
       "52436             398                                     NaN  \n",
       "52437             398                                     NaN  \n",
       "52438             492                                     NaN  \n",
       "52439             619                                     NaN  \n",
       "52440             619                                     NaN  \n",
       "52441             728                                     NaN  \n",
       "52442             704                                     NaN  \n",
       "52443             486                                     NaN  \n",
       "52444             527                                     NaN  \n",
       "52445             240                                     NaN  \n",
       "52446             802                                     NaN  \n",
       "52447             863                                     NaN  \n",
       "52448             881                                     NaN  \n",
       "52449             760                                     NaN  \n",
       "52450             760                                     NaN  \n",
       "\n",
       "[52451 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('http://www.waterrights.utah.gov/tmpdata/O1747696.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 70: expected 6 fields, saw 9\n",
      "Skipping line 144: expected 6 fields, saw 9\n",
      "Skipping line 155: expected 6 fields, saw 9\n",
      "Skipping line 278: expected 6 fields, saw 7\n",
      "Skipping line 279: expected 6 fields, saw 9\n",
      "Skipping line 344: expected 6 fields, saw 9\n",
      "Skipping line 353: expected 6 fields, saw 9\n",
      "Skipping line 400: expected 6 fields, saw 9\n",
      "Skipping line 410: expected 6 fields, saw 9\n",
      "Skipping line 452: expected 6 fields, saw 9\n",
      "Skipping line 504: expected 6 fields, saw 9\n",
      "Skipping line 594: expected 6 fields, saw 9\n",
      "Skipping line 614: expected 6 fields, saw 9\n",
      "Skipping line 616: expected 6 fields, saw 9\n",
      "Skipping line 635: expected 6 fields, saw 12\n",
      "Skipping line 765: expected 6 fields, saw 9\n",
      "Skipping line 828: expected 6 fields, saw 9\n",
      "Skipping line 1035: expected 6 fields, saw 12\n",
      "Skipping line 1171: expected 6 fields, saw 9\n",
      "Skipping line 1361: expected 6 fields, saw 9\n",
      "Skipping line 1382: expected 6 fields, saw 9\n",
      "Skipping line 1441: expected 6 fields, saw 12\n",
      "Skipping line 1926: expected 6 fields, saw 9\n",
      "Skipping line 1968: expected 6 fields, saw 12\n",
      "Skipping line 2024: expected 6 fields, saw 12\n",
      "Skipping line 2027: expected 6 fields, saw 12\n",
      "Skipping line 2030: expected 6 fields, saw 12\n",
      "Skipping line 2059: expected 6 fields, saw 9\n",
      "Skipping line 2137: expected 6 fields, saw 12\n",
      "Skipping line 2257: expected 6 fields, saw 9\n",
      "Skipping line 2283: expected 6 fields, saw 9\n",
      "Skipping line 2320: expected 6 fields, saw 12\n",
      "Skipping line 2547: expected 6 fields, saw 7\n",
      "Skipping line 2578: expected 6 fields, saw 8\n",
      "Skipping line 2622: expected 6 fields, saw 7\n",
      "Skipping line 2723: expected 6 fields, saw 8\n",
      "Skipping line 2730: expected 6 fields, saw 7\n",
      "Skipping line 2851: expected 6 fields, saw 9\n",
      "Skipping line 2895: expected 6 fields, saw 9\n",
      "Skipping line 3002: expected 6 fields, saw 9\n",
      "Skipping line 3016: expected 6 fields, saw 9\n",
      "Skipping line 3101: expected 6 fields, saw 9\n",
      "Skipping line 3108: expected 6 fields, saw 9\n",
      "Skipping line 3127: expected 6 fields, saw 9\n",
      "Skipping line 3202: expected 6 fields, saw 9\n",
      "Skipping line 3210: expected 6 fields, saw 9\n",
      "Skipping line 3246: expected 6 fields, saw 9\n",
      "Skipping line 3279: expected 6 fields, saw 9\n",
      "Skipping line 3344: expected 6 fields, saw 9\n",
      "Skipping line 3346: expected 6 fields, saw 9\n",
      "Skipping line 3349: expected 6 fields, saw 9\n",
      "Skipping line 3352: expected 6 fields, saw 9\n",
      "Skipping line 3378: expected 6 fields, saw 9\n",
      "Skipping line 3406: expected 6 fields, saw 9\n",
      "Skipping line 3454: expected 6 fields, saw 9\n",
      "Skipping line 3476: expected 6 fields, saw 9\n",
      "Skipping line 3480: expected 6 fields, saw 9\n",
      "Skipping line 3483: expected 6 fields, saw 9\n",
      "Skipping line 3486: expected 6 fields, saw 9\n",
      "Skipping line 3616: expected 6 fields, saw 9\n",
      "Skipping line 3635: expected 6 fields, saw 9\n",
      "Skipping line 3651: expected 6 fields, saw 9\n",
      "Skipping line 3661: expected 6 fields, saw 9\n",
      "Skipping line 3667: expected 6 fields, saw 9\n",
      "Skipping line 3692: expected 6 fields, saw 9\n",
      "Skipping line 3699: expected 6 fields, saw 9\n",
      "Skipping line 3751: expected 6 fields, saw 9\n",
      "Skipping line 3771: expected 6 fields, saw 12\n",
      "Skipping line 3799: expected 6 fields, saw 9\n",
      "Skipping line 3849: expected 6 fields, saw 9\n",
      "Skipping line 3894: expected 6 fields, saw 12\n",
      "Skipping line 3897: expected 6 fields, saw 9\n",
      "Skipping line 3933: expected 6 fields, saw 9\n",
      "Skipping line 3979: expected 6 fields, saw 9\n",
      "Skipping line 4004: expected 6 fields, saw 9\n",
      "Skipping line 4044: expected 6 fields, saw 9\n",
      "Skipping line 4047: expected 6 fields, saw 9\n",
      "Skipping line 4065: expected 6 fields, saw 9\n",
      "Skipping line 4369: expected 6 fields, saw 12\n",
      "Skipping line 4401: expected 6 fields, saw 9\n",
      "Skipping line 4404: expected 6 fields, saw 9\n",
      "Skipping line 4546: expected 6 fields, saw 12\n",
      "Skipping line 4553: expected 6 fields, saw 9\n",
      "Skipping line 4569: expected 6 fields, saw 9\n",
      "Skipping line 4602: expected 6 fields, saw 9\n",
      "Skipping line 4609: expected 6 fields, saw 9\n",
      "Skipping line 4625: expected 6 fields, saw 9\n",
      "Skipping line 4640: expected 6 fields, saw 9\n",
      "Skipping line 4643: expected 6 fields, saw 9\n",
      "Skipping line 4646: expected 6 fields, saw 9\n",
      "Skipping line 4677: expected 6 fields, saw 9\n",
      "Skipping line 4722: expected 6 fields, saw 9\n",
      "Skipping line 4725: expected 6 fields, saw 9\n",
      "Skipping line 4762: expected 6 fields, saw 9\n",
      "Skipping line 4771: expected 6 fields, saw 12\n",
      "Skipping line 4773: expected 6 fields, saw 9\n",
      "\n"
     ]
    },
    {
     "ename": "CParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCParserError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0542f9f14854>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://www.waterrights.utah.gov/tmpdata/O1398367.txt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merror_bad_lines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/pi/Documents/Github/venv/local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pi/Documents/Github/venv/local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m _parser_defaults = {\n",
      "\u001b[1;32m/home/pi/Documents/Github/venv/local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    813\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skip_footer not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 815\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    816\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'as_recarray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pi/Documents/Github/venv/local/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1312\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1314\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1315\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.read (pandas/parser.c:8748)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_low_memory (pandas/parser.c:9003)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._read_rows (pandas/parser.c:9731)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._tokenize_rows (pandas/parser.c:9602)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.raise_parser_error (pandas/parser.c:23325)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mCParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "pd.read_csv('http://www.waterrights.utah.gov/tmpdata/O1398367.txt',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connections = pd.concat(conn)\n",
    "connections.reset_index(inplace=True)\n",
    "connections.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "connections.drop(['level_1','nan'],axis=1,inplace=True)\n",
    "connections = connections[(connections['Year']<datetime.today().year)&(connections['Year']>1830)]\n",
    "connections = connections[connections.Total < 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This must be done after scraping or you will throw a host error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#engineroute = \"H:/Google Drive/WORK/Groundwater Chemistry\"\n",
    "engineroute = \"C:/Users/Brooke/Downloads/\"\n",
    "sys.path.append(engineroute)\n",
    "import enginegetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = enginegetter.getEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems and Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the systems made up of the sources.  They are often cities or water agencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "systems.to_sql(con=engine, name='systems', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the water use sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources.to_sql(con=engine, name='sources', if_exists='replace', flavor='mysql', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts the amount of water use by each source in ac-ft/mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srctake.to_sql(con=engine, name='sourceuse', if_exists='replace', flavor='mysql',chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts the amount of water use by each system in ac-ft/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuseData.to_sql(con=engine, name='systemuse', if_exists='replace', flavor='mysql',chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts number of connections in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connections.to_sql(con=engine, name='systemconnections', if_exists='replace', flavor='mysql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waterlevels.to_sql(con=engine, name='waterlevels', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borehole.to_sql(con=engine, name='borehole', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driller.to_sql(con=engine, name='driller', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lithlog.to_sql(con=engine, name='lithlog', if_exists='replace', flavor='mysql',index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "construction.to_sql(con=engine, name='construction', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "screendf.to_sql(con=engine, name='wellscreens', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellTrans.to_sql(con=engine, name='pumpingtests', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ArcPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Locate ArcPy and add it to the path\n",
    "Created on 13 Feb 2015\n",
    "@author: Jamesramm\n",
    "https://github.com/JamesRamm/archook/blob/master/archook.py\n",
    "'''\n",
    "import _winreg\n",
    "import sys\n",
    "from os import path\n",
    "def locate_arcgis():\n",
    "  '''\n",
    "  Find the path to the ArcGIS Desktop installation.\n",
    "  Keys to check:\n",
    "  HLKM/SOFTWARE/ESRI/ArcGIS 'RealVersion' - will give the version, then we can use\n",
    "  that to go to\n",
    "  HKLM/SOFTWARE/ESRI/DesktopXX.X 'InstallDir'. Where XX.X is the version\n",
    "  We may need to check HKLM/SOFTWARE/Wow6432Node/ESRI instead\n",
    "  '''\n",
    "  try:\n",
    "    key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                          'SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\ArcGIS', 0)\n",
    "\n",
    "    version = _winreg.QueryValueEx(key, \"RealVersion\")[0][:4]\n",
    "\n",
    "    key_string = \"SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\Desktop{0}\".format(version)\n",
    "    desktop_key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                                  key_string, 0)\n",
    "\n",
    "    install_dir = _winreg.QueryValueEx(desktop_key, \"InstallDir\")[0]\n",
    "    return install_dir\n",
    "  except WindowsError:\n",
    "    raise ImportError(\"Could not locate the ArcGIS directory on this machine\")\n",
    "\n",
    "def get_arcpy():  \n",
    "  '''\n",
    "  Allows arcpy to imported on 'unmanaged' python installations (i.e. python installations\n",
    "  arcgis is not aware of).\n",
    "  Gets the location of arcpy and related libs and adds it to sys.path\n",
    "  '''\n",
    "  install_dir = locate_arcgis()  \n",
    "  arcpy = path.join(install_dir, \"arcpy\")\n",
    "  # Check we have the arcpy directory.\n",
    "  if not path.exists(arcpy):\n",
    "    raise ImportError(\"Could not find arcpy directory in {0}\".format(install_dir))\n",
    "\n",
    "  # First check if we have a bin64 directory - this exists when arcgis is 64bit\n",
    "  bin_dir = path.join(install_dir, \"bin64\")\n",
    "  if not path.exists(bin_dir):\n",
    "    # Fall back to regular 'bin' dir otherwise.\n",
    "    bin_dir = path.join(install_dir, \"bin\")\n",
    "\n",
    "  scripts = path.join(install_dir, \"ArcToolbox\", \"Scripts\")  \n",
    "  sys.path.extend([arcpy, bin_dir, scripts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_arcpy()\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileloc = r'C:/GIS/WR_DATA.gdb/'\n",
    "\n",
    "def df2gdb(df,fileloc,name):\n",
    "    x = np.array(np.rec.fromrecords(df.values))\n",
    "    names = df.dtypes.index.tolist()\n",
    "    x.dtype.names = tuple(names)\n",
    "    arcpy.da.NumPyArrayToTable(x, fileloc+name)\n",
    "\n",
    "def df2csv2gdb(df,fileloc,csvloc,name,ind=False):\n",
    "    df.to_csv(csvloc,index=ind)\n",
    "    arcpy.TableToTable_conversion(csvloc, fileloc, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems and Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(systems,fileloc,'systems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(sources,fileloc,'sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(systemuseData,fileloc,'systemuse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(waterlevels,fileloc,'waterlevels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(borehole,fileloc,'borehole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(driller,fileloc,'driller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2csv2gdb(lithlog,fileloc,r'C:/GIS/lithlogs.csv','lithlogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(construction,fileloc,'construction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(screendf,fileloc,'screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(wellTrans,fileloc,'spCapTrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(connections,fileloc,'connections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "systemuseData.groupby('Year')[['Total','Domestic','Industrial','Commercial']].sum().plot()\n",
    "plt.xlim(1980,2020)\n",
    "plt.ylabel('Use (ac-ft)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuseData.groupby('Year')['Total'].sum().plot()\n",
    "plt.xlim(1980,2020)\n",
    "plt.ylabel('Use (ac-ft)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('C:\\\\PROJECTS\\\\WR_DATA\\\\' + 'systems_and_sources.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "systems.to_excel(writer, sheet_name='systems')\n",
    "sources.to_excel(writer, sheet_name='sources')\n",
    "srctakeData.to_excel(writer, sheet_name='sourcetake')\n",
    "systemuseData.to_excel(writer, sheet_name='system_use')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
