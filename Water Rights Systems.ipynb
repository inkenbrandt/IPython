{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These scripts scrape data from the Utah Water Rights website, saves the data to text files, then parses the text files into a MySQL database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import urllib2\n",
    "from urllib2 import urlopen\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as tick\n",
    "import scipy.stats as sp\n",
    "import statsmodels.api as sm\n",
    "from pandas.stats.api import ols\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from pylab import rcParams\n",
    "import platform\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import urllib\n",
    "import HTMLParser\n",
    "from cStringIO import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose output routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "route = 'C:/PROJECTS/WR_DATA/'\n",
    "wellpath = 'C:/PROJECTS/WR_DATA/RawWellogs/'\n",
    "syspath = 'C:/PROJECTS/WR_DATA/RawSystems/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parser and Scraper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup(url):\n",
    "    # opens webpage for use in BeautifulSoup    \n",
    "    html = urlopen(url).read()\n",
    "    return BeautifulSoup(html, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Log Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrapes well Logs from Water Rights website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Water Rights win number to begin search\n",
    "winbegin = 34000\n",
    "space = 1000\n",
    "winend = winbegin + space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while winbegin < 60000:\n",
    "       \n",
    "    # opens waterrights webpage by win   \n",
    "    for i in range(winbegin,winend):\n",
    "        try:\n",
    "            win = str(i)\n",
    "            soup = make_soup('http://waterrights.utah.gov/cgi-bin/docview.exe?Folder=welllog'+str(i))\n",
    "            souplist = soup.find('a', href=re.compile('^http://waterrights.utah.gov/docSys/v907/.*'))['href']\n",
    "            soupsite = make_soup(souplist)\n",
    "            souptext = soupsite.get_text()\n",
    "            g = path + 'log' + str(win).zfill(5) + '.txt'    \n",
    "            b = open(g, 'w')\n",
    "            b.write(souptext.encode('utf-8'))\n",
    "            b.close()\n",
    "        except TypeError:        \n",
    "            pass\n",
    "    \n",
    "    winbegin = winend\n",
    "    winend = winbegin + space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Water System Use Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From: http://www.waterrights.utah.gov/wateruse/WaterUseList.asp<br/>\n",
    "Example Pages of Input:<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=Indview&SYSTEM_ID=11247<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=Mgtview&SYSTEM_ID=11228<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def systemscraper(winbegin,winfinish,space,prefix,path):\n",
    "    '''\n",
    "    Systematically progresses though integer id numbers at the end of Water Rights URL to find system pages, \n",
    "    then saves those pages to text files.\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    winbegin = integer value to start search\n",
    "    space = number of integers to search at a time\n",
    "    winfinish = integer value to end search\n",
    "    prefix = subset of systems to search (Modinfo= value in URL); can be Pws, Ind, or Mgt\n",
    "    path = place to store resulting text files\n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    text files in path labeled with corresponding integer values\n",
    "    '''\n",
    "    winend = winbegin + space\n",
    "\n",
    "    while winbegin < winfinish:\n",
    "\n",
    "        systemnm = []\n",
    "\n",
    "        # opens waterrights webpage by win   \n",
    "        for i in range(winbegin,winend):\n",
    "            try:\n",
    "                htmlplace = 'http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo=' + str(prefix) + 'view&SYSTEM_ID='+str(i)\n",
    "                soup = make_soup(htmlplace).get_text()\n",
    "                if \"ERROR: Use UNITS undefined\" in soup or len(soup) < 1000:\n",
    "                    pass\n",
    "                else:\n",
    "                    systemnm.append(str(i))\n",
    "                    g = path + str(prefix) + str(i).zfill(6) + '.txt'\n",
    "                    b = open(g, 'w')\n",
    "                    b.write(soup.encode('utf-8').strip())   \n",
    "                    b.close()\n",
    "            except TypeError:        \n",
    "                pass\n",
    "\n",
    "        winbegin = winend\n",
    "        winend = winbegin + space\n",
    "    print(\"Scanned %s to %s\"%(prefix,winfinish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "systems = ['Pws','Ind','Mgt']\n",
    "\n",
    "for i in systems:\n",
    "    systemscraper(0,3000,1000,i,syspath)\n",
    "    systemscraper(10000,13000,1000,i,syspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Well Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code searches through text captures of Water Rights html well files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = wellpath + '*.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def raises(exception_types, func, *args, **kw):\n",
    "    try:\n",
    "        func(*args, **kw)\n",
    "    except exception_types:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tparser(blurb):\n",
    "    '''\n",
    "    parses a snippet of text from gettext by removing and replaces extra spaces and return characters\n",
    "    '''\n",
    "    blurb = re.sub('\\r\\n      +', '\\n',str(blurb))\n",
    "    blurb = re.sub('\\r\\n +','\\r\\n',blurb)\n",
    "    blurb = re.sub(',',';',blurb)\n",
    "    blurb = re.sub(' +',',',blurb)\n",
    "    blurb = re.sub('\\r\\n','\\n',blurb)\n",
    "    blurb = re.sub('\\n\\n','\\n',blurb)\n",
    "    return blurb\n",
    "\n",
    "def gettext(strttext,endtext,snip):\n",
    "    '''\n",
    "    selects a subset of text by searching the text for a beginning string and an ending string\n",
    "    \n",
    "    INPUT\n",
    "    -----\n",
    "    strttext = string to find that begins text subset\n",
    "    endtext = string to find that ends the text subset\n",
    "    snip = text to subset\n",
    "    \n",
    "    OUTPUT\n",
    "    ------\n",
    "    b = subset of text; returns np.nan if no strttext is found\n",
    "    '''\n",
    "    \n",
    "    b = snip[snip.find(strttext)+len(strttext):snip.find(endtext,snip.find(strttext))].strip()\n",
    "    if snip.find(strttext) == -1:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Water Level Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "wl = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    wellcon = gettext(' WATER LEVEL DATA:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if raises(ValueError, int, rv[j][0:21].strip(' ')[0:2])==False:\n",
    "                    rv[j] = win + ',' + rv[j][0:21] + ',' + rv[j][30:38].replace(',',';').strip(' ') + ',' + rv[j][38:].strip(' ')\n",
    "                \n",
    "                    rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                else:\n",
    "                    pass\n",
    "            wl.append('\\n'.join(rr))\n",
    "\n",
    "levs = '\\n'.join(wl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waterlevels = pd.read_csv(StringIO(levs),names=['WIN','Date','Level','Method'],parse_dates=['Date'])\n",
    "waterlevels.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "br = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    wellcon = gettext(' BOREHOLE INFORMATION:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if raises(ValueError, int, rv[j][0:21].strip(' ')[0:2])==False:\n",
    "                    rv[j] = win + ',' + rv[j][0:17] + ',' + rv[j][17:23] + ',' + rv[j][23:29]+ ',' + rv[j][29:58]+ ',' + rv[j][58:]\n",
    "                \n",
    "                    rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                    #print(rv[j])\n",
    "                else:\n",
    "                    pass\n",
    "            br.append('\\n'.join(rr))\n",
    "   \n",
    "bore = '\\n'.join(br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "borehole = pd.read_csv(StringIO(bore),names=['WIN','From_ft','To_ft','Diameter','Method','Fluid'])\n",
    "borehole.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drilling Activity Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "\n",
    "rr = []\n",
    "for f in glob.glob(filepath):\n",
    "    \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    wellcon = gettext(' DRILLER ACTIVITIES:','\\r\\n\\r\\n',text)\n",
    "    \n",
    "    #print wellcon\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            \n",
    "            act1 = str(gettext('ACTIVITY # 1 ','\\r\\n\\r\\n',wellcon))\n",
    "            actnm1 = str(gettext('ACTIVITY # 1 ','\\r\\n',wellcon)).strip(' ')\n",
    "            drllr1 = str(gettext('DRILLER: ','LICENSE #:',act1)).replace(',',' ').strip(' ')\n",
    "            lic1 =  str(gettext('LICENSE #:','\\r\\n',act1)).strip(' ')\n",
    "            strt1 = str(gettext('START DATE: ','COMPLETION DATE: ',act1)).strip(' ')\n",
    "            comp1 = str(gettext('COMPLETION DATE: ','\\r\\n',act1)).strip(' ')\n",
    "            rr.append(win+','+actnm1+','+drllr1+','+lic1+','+strt1+','+comp1)\n",
    "            #print win+','+actnm1+','+drllr1+','+lic1+','+strt1+','+comp1\n",
    "            if 'ACTIVITY # 2' in wellcon: \n",
    "                act2 = str(gettext('ACTIVITY # 2 ','\\r\\n\\r\\n',wellcon))\n",
    "                actnm2 = str(gettext('ACTIVITY # 2 ','\\r\\n',wellcon)).strip(' ')\n",
    "                drllr2 = str(gettext('DRILLER: ','LICENSE #:',act2)).replace(',',' ').strip(' ')\n",
    "                lic2 =  str(gettext('LICENSE #:','\\r\\n',act2)).strip(' ')\n",
    "                strt2 = str(gettext('START DATE: ','COMPLETION DATE: ',act2)).strip(' ')\n",
    "                comp2 = str(gettext('COMPLETION DATE: ','\\r\\n',act2)).strip(' ')\n",
    "                rr.append(win+','+actnm2+','+drllr2+','+lic2+','+strt2+','+comp2)\n",
    "    \n",
    "            if 'ACTIVITY # 3' in wellcon:\n",
    "                act3 = str(gettext('ACTIVITY # 3 ','\\r\\n\\r\\n',wellcon))\n",
    "                actnm3 = str(gettext('ACTIVITY # 3 ','\\r\\n',wellcon)).strip(' ')\n",
    "                drllr3 = str(gettext('DRILLER: ','LICENSE #:',act3)).replace(',',' ').strip(' ')\n",
    "                lic3 =  str(gettext('LICENSE #:','\\r\\n',act3)).strip(' ')\n",
    "                strt3 = str(gettext('START DATE: ','COMPLETION DATE: ',act3)).strip(' ')\n",
    "                comp3 = str(gettext('COMPLETION DATE: ','\\r\\n',act3)).strip(' ')\n",
    "                rr.append(win+','+actnm3+','+drllr3+','+lic3+','+strt3+','+comp3)\n",
    "drill = '\\n'.join(rr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driller = pd.read_csv(StringIO(drill),names=['WIN','activity','driller','license','start','completion'],index_col=False)#,parse_dates=['start','completion'])\n",
    "driller.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lithology Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "lit = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    litho = gettext(' LITHOLOGY:','\\r\\n\\r\\n',text)\n",
    "    #print wellcon\n",
    "    if litho is not np.nan:\n",
    "        if len(litho) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = litho.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                if j == len(rv):\n",
    "                    rv[j] = win + ',' + rv[j][0:7] + ',' + rv[j][7:13].strip(' ') + ',' + rv[j][13:95].replace(',',';').strip(' ') + ',' + rv[j][95:108].strip(' ') +','+rv[j][108:].strip(' ').replace(',',';').replace('  ',' ') + ','\n",
    "                else:\n",
    "                    if len(rv[j][0:8].strip(' ')) < 1:\n",
    "                        pass\n",
    "                    else:\n",
    "                        rv[j] = win + ',' + rv[j][0:7] + ',' + rv[j][7:13].strip(' ') + ',' + rv[j][13:95].replace(',',';').strip(' ') + ',' + rv[j][95:108].strip(' ') +','+rv[j][108:].strip(' ').replace(',',';').replace('  ',' ') + ','\n",
    "                        try:\n",
    "                            if len(rv[j+1][0:8].strip(' ')) < 1:\n",
    "                                if len(rv[j+1].replace('  ',' ').strip(' '))<350:\n",
    "                                    rv[j] = rv[j] + rv[j+1].replace(',',';').replace('  ',' ').strip(' ')\n",
    "                                else:\n",
    "                                    rv[j] = rv[j] + rv[j+1].replace(',',';').replace('  ',' ').strip(' ')[0:350]\n",
    "                        except(IndexError):\n",
    "                            pass\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            lit.append('\\n'.join(rr))\n",
    "\n",
    "                \n",
    "   \n",
    "lith = '\\n'.join(lit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lithlog = pd.read_csv(StringIO(lith),names=['WIN','From_ft','To_ft','Material','Color','Rock Type','Comment'])\n",
    "lithlog.drop_duplicates(inplace=True)\n",
    "lithlog.From_ft = pd.to_numeric(lithlog.From_ft, errors='coerce')\n",
    "lithlog.To_ft = pd.to_numeric(lithlog.To_ft, errors='coerce')\n",
    "lithlog.dropna(subset=['From_ft','To_ft'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lithsort(lith, x):      \n",
    "    if str(lith).lower() in str(x).lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def lithsorth(lith, x):\n",
    "    if 'other' in str(x[0]).lower():\n",
    "        b = str(x[0]).lower() + ' ' + str(x[1]).upper()\n",
    "    else:\n",
    "        b = x[0]\n",
    "    if str(lith).lower() in str(b).lower():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "    \n",
    "lithlog['low_perm'] = lithlog['Material'].apply(lambda x: lithsort('LOW-PERMEABILITY', x),1)\n",
    "lithlog['high_perm'] = lithlog['Material'].apply(lambda x: lithsort('HIGH-PERMEABILITY', x),1)\n",
    "lithlog['clay'] = lithlog['Material'].apply(lambda x: lithsort('clay', x),1)\n",
    "lithlog['silt'] = lithlog['Material'].apply(lambda x: lithsort('silt', x),1)\n",
    "lithlog['sand'] = lithlog['Material'].apply(lambda x: lithsort('sand', x),1)\n",
    "lithlog['gravel'] = lithlog['Material'].apply(lambda x: lithsort('gravel', x),1)\n",
    "lithlog['cobbles'] = lithlog['Material'].apply(lambda x: lithsort('cobbles', x),1)\n",
    "lithlog['boulders'] = lithlog['Material'].apply(lambda x: lithsort('boulders', x),1)\n",
    "lithlog['hardpan'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('hardpan', x),1)\n",
    "lithlog['conglomerate'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('conglomerate', x),1)\n",
    "lithlog['bedrock'] = lithlog[['Material','Comment']].apply(lambda x: lithsorth('bedrock', x),1)\n",
    "lithlog['other'] = lithlog['Material'].apply(lambda x: lithsort('other', x),1)\n",
    "lithlog['water_bearing'] = lithlog['Material'].apply(lambda x: lithsort('water-bearing', x),1)\n",
    "\n",
    "\n",
    "def unitassign(x):\n",
    "    clay = x[0]\n",
    "    silt = x[1]\n",
    "    sand = x[2]\n",
    "    gravel = x[3]\n",
    "    cobbles = x[4]\n",
    "    boulders = x[5]\n",
    "    hardpan = x[6]\n",
    "    conglomerate = x[7]\n",
    "    bedrock = x[8]\n",
    "    other = x[9]\n",
    "    unitlist = [clay,silt,sand,gravel,cobbles,boulders, hardpan,conglomerate,bedrock,other]\n",
    "    unitindex = ['clay','silt','sand','gravel','cobbles','boulders', 'hardpan','conglomerate','bedrock','other']\n",
    "    unitsum = np.sum(unitlist)\n",
    "    j =str(\"\")\n",
    "    for i in range(len(unitlist)):\n",
    "        if unitlist[i] == 1:\n",
    "            if len(j)==0:\n",
    "                j = unitindex[i]\n",
    "            else:\n",
    "                j = j + \"-\" + unitindex[i]\n",
    "    return j    \n",
    "\n",
    "lithlog.units = lithlog[['clay','silt','sand','gravel','cobbles','boulders', 'hardpan','conglomerate','bedrock','other']].apply(lambda x: unitassign(x),1)\n",
    "\n",
    "consdict = {'other':'other', 'boulders':'gravel', 'gravel':'gravel', 'sand-gravel-cobbles':'sand-gravel',\n",
    "            'sand-gravel-cobbles-boulders':'sand-gravel', 'clay-boulders':'clay-gravel', \n",
    "            'clay-gravel-boulders':'clay-gravel', 'gravel-conglomerate':'conglomerate', 'cobbles':'gravel',\n",
    "            'gravel-cobbles':'gravel', 'gravel-boulders':'gravel', 'clay-gravel-cobbles-boulders':'clay-gravel', \n",
    "            'gravel-cobbles-boulders':'gravel', 'clay-cobbles-boulders':'clay-gravel', \n",
    "            'clay-cobbles':'clay-gravel','clay-sand-gravel-cobbles':'clay-gravel', \n",
    "            'clay-hardpan':'hardpan', 'cobbles-boulders':'gravel', 'clay-gravel-cobbles':'clay-gravel', \n",
    "            'clay-conglomerate':'conglomerate', 'clay-silt-sand-gravel-conglomerate':'conglomerate', \n",
    "            'sand-gravel-boulders':'sand-gravel','sand-boulders':'sand-gravel','clay-silt-gravel':'clay-gravel',\n",
    "           'clay-silt-sand':'clay-sand','clay-silt':'clay-sand','clay-sand-gravel':'clay-gravel',\n",
    "           'silt-sand':'sand','clay-silt-gravel-cobbles':'clay-gravel','silt-sand-gravel':'sand-gravel'}\n",
    "\n",
    "lithlog['unitssimp'] = lithlog.units.apply(lambda x:consdict.get(x,x),1)\n",
    "\n",
    "\n",
    "def otherassign(x):\n",
    "    if x[0] == 'other' or x[0]=='':\n",
    "        if str(x[1]).lower().find('soil') >-1:\n",
    "            return 'soil'\n",
    "        elif str(x[1]).lower().find('overburden') >-1:\n",
    "            return 'soil'\n",
    "        elif str(x[1]).lower().find('limestone') >-1:\n",
    "            return 'limestone'\n",
    "        elif str(x[1]).lower().find('shale') >-1:\n",
    "            return 'shale'\n",
    "        elif str(x[1]).lower().find('cemented') >-1:\n",
    "            return 'conglomerate'\n",
    "        elif str(x[1]).lower().find('conglomerate') >-1:\n",
    "            return 'conglomerate'\n",
    "        else:\n",
    "            return ''\n",
    "    elif x[0] == 'bedrock':\n",
    "        if str(x[1]).lower().find('limestone') >-1:\n",
    "            return 'limestone'\n",
    "        elif str(x[1]).lower().find('shale') >-1:\n",
    "            return 'shale'\n",
    "        elif str(x[1]).lower().find('cemented') >-1:\n",
    "            return 'conglomerate'\n",
    "        elif str(x[1]).lower().find('conglomerate') >-1:\n",
    "            return 'conglomerate'\n",
    "        else:\n",
    "            return 'bedrock'\n",
    "    else:\n",
    "        return x[0]\n",
    "\n",
    "lithlog['unitssimp'] = lithlog[['unitssimp','Comment']].apply(lambda x:otherassign(x),1)\n",
    "\n",
    "unitnumber = {'soil':0, 'sand-gravel':1, 'clay':2, 'gravel':1, 'sand':4, 'clay-gravel':5,\n",
    "              'clay-sand':3, 'conglomerate':7, 'hardpan':2, 'bedrock':6, 'limestone':6,\n",
    "              'sand-gravel-other':1, 'clay-silt-sand-gravel':3, 'clay-silt-other':2,\n",
    "              'silt':2, 'clay-other':2, 'shale':2}\n",
    "lithlog['unitnumber'] = lithlog['unitssimp'].apply(lambda x: unitnumber.get(x,8),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "const = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "\n",
    "    rev = []\n",
    "\n",
    "    wellcon = gettext('CASING:','\\r\\n\\r\\n',text)\n",
    "\n",
    "    if wellcon is not np.nan:\n",
    "        if len(wellcon) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = wellcon.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           From                    To                                          Material                                    Gage                        Diam                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:20].replace('+','-') + ',' + rv[j][20:24].strip(' ') + ',' + rv[j][24:45].replace(',',';').strip(' ') + ',' + rv[j][45:57].strip(' ') +','+rv[j][57:].strip(' ').replace('  ',' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            const.append('\\n'.join(rr))\n",
    "\n",
    "\n",
    "\n",
    "constList = '\\n'.join(const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "construction = pd.read_csv(StringIO(constList),names=['WIN','From_ft','To_ft','Material','Gage_in','Diameter_in'])\n",
    "construction.drop_duplicates(inplace=True)\n",
    "construction.From_ft = pd.to_numeric(construction.From_ft,errors='coerce')\n",
    "construction.To_ft = pd.to_numeric(construction.To_ft,errors='coerce')\n",
    "construction.Diameter_in = pd.to_numeric(construction.Diameter_in,errors='coerce')\n",
    "construction.dropna(subset=['WIN','From_ft','To_ft'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Screen Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "srn = []\n",
    "for f in glob.glob(filepath):    \n",
    "    text = open(f).read()   \n",
    "\n",
    "    scrntxt = gettext('SCREENS/PERFORATIONS:','\\r\\n\\r\\n',text)\n",
    "    \n",
    "    if scrntxt is not np.nan:\n",
    "        if len(scrntxt) > 10:    \n",
    "\n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = scrntxt.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           From                    To                                          Type                                                Slot                        Diam                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:18].replace('+','-') + ',' + rv[j][18:25].strip(' ') + ',' + rv[j][25:53].replace(',',';').strip(' ') + ',' + rv[j][53:69].strip(' ') +','+ rv[j][69:97].strip(' ').replace('  ',' ') +','+ rv[j][97:].replace(',',';').strip(' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            srn.append('\\n'.join(rr))\n",
    "            \n",
    "scrrn = '\\n'.join(srn)\n",
    "\n",
    "screendf = pd.read_csv(StringIO(scrrn),names=['WIN','From_ft','To_ft','Screen Type',\n",
    "                                    'Slot_Size_in','Scrn_Diam_in','Perfs'])\n",
    "screendf.drop_duplicates(inplace=True)\n",
    "\n",
    "screendf.From_ft = pd.to_numeric(screendf.From_ft,errors='coerce')\n",
    "screendf.To_ft = pd.to_numeric(screendf.To_ft,errors='coerce')\n",
    "\n",
    "scrnInt = screendf.groupby('WIN').agg({'From_ft':np.min, 'To_ft':np.min})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrnInt.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pumping Test Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = wellpath +'*.txt'\n",
    "\n",
    "pmp = []\n",
    "for f in glob.glob(filepath): \n",
    "    text = open(f).read()    \n",
    "\n",
    "    # grab section out of each text file for parsing\n",
    "    \n",
    "    rr =[]\n",
    "    welltest = gettext('WELL TESTS:','\\r\\n\\r\\n\\r\\n ',text)\n",
    "    #print wellcon\n",
    "    if welltest is not np.nan:\n",
    "        if len(welltest) > 10:    \n",
    "            win = str(int(os.path.split(f)[1][3:8])).zfill(5)\n",
    "            rv = welltest.split('\\n')\n",
    "            rr = []\n",
    "            for j in range(2,len(rv)):\n",
    "                #       WIN           DATE                    Test Method                                  Yield                                    Drawdown                        Time pump                                                          \n",
    "                rv[j] = win + ',' + rv[j][0:22] + ',' + rv[j][22:41].replace(',',';').strip(' ') + ',' + rv[j][41:54].strip(' ') + ',' + rv[j][54:70].strip(' ') +','+rv[j][70:].strip(' ').replace('  ',' ')\n",
    "\n",
    "                rr.append(rv[j].replace('\\r','').replace('  ',' ').strip(' '))\n",
    "                \n",
    "                #print(rr)\n",
    "            pmp.append('\\n'.join(rr))\n",
    "\n",
    "                \n",
    "   \n",
    "pump = '\\n'.join(pmp)\n",
    "\n",
    "pumpingtests = pd.read_csv(StringIO(pump), names=['WIN', 'Date', 'Method', 'Yield_cfs', \n",
    "                                                  'Drawdown_ft', 'Pump_Dur_hr'])#,parse_dates=['Date'])\n",
    "pumpingtests.drop_duplicates(inplace=True)\n",
    "pumpingtests['Yield_cfs'] = pd.to_numeric(pumpingtests.Yield_cfs, errors='coerce')\n",
    "pumpingtests['Drawdown_ft'] = pd.to_numeric(pumpingtests.Drawdown_ft, errors='coerce')\n",
    "pumpingtests['Pump_Dur_hr'] = pd.to_numeric(pumpingtests.Pump_Dur_hr, errors='coerce')\n",
    "pumpingtests.dropna(subset=['Yield_cfs','Drawdown_ft','Pump_Dur_hr'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pumpT = pd.merge(pumpingtests, construction, on='WIN',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getTrans(x,S):\n",
    "    Q = float(x[0])*86400.0\n",
    "    d = float(x[1])\n",
    "    t = float(x[2])/24.0\n",
    "    if d == 0:\n",
    "        sc = Q/0.1\n",
    "    else:\n",
    "        sc = Q/d\n",
    "        \n",
    "    r = float(x[3])/24.0\n",
    "    if r == 0:\n",
    "        return np.nan\n",
    "\n",
    "    else:\n",
    "        T0 = 100.0\n",
    "        delt = 100.0\n",
    "        while abs(delt) > 0.01:\n",
    "            T = (sc/(4*np.pi))*(np.log((2.25*T0*t)/(r*r*S)))\n",
    "            delt = T - T0\n",
    "            T0 = T\n",
    "        return T\n",
    "             \n",
    "S = 0.0002\n",
    "\n",
    "pumpT['trans'] = pumpT[['Yield_cfs','Drawdown_ft','Pump_Dur_hr','Diameter_in']].apply(lambda x: getTrans(x,S),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pumpT.drop(['From_ft','To_ft','Material','Gage_in'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellTrans = pd.merge(pumpT, scrnInt, on='WIN', how='left')\n",
    "wellTrans.dropna(subset=['trans'],inplace=True)\n",
    "wellTrans = wellTrans[(wellTrans.Drawdown_ft > 0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System and Source Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathname = 'D:/PROJECTS/WR_DATA/RawSystems/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = glob.glob(pathname +'*.txt')\n",
    "\n",
    "sourcet, conn, use = {}, {}, {}\n",
    "\n",
    "indcode, systype, sysnum, link, sysname, city, county, syscat, huc, pwsid, deqcat, numberofsources = [],[],[],[],[],[],[],[],[],[],[],[]\n",
    "source, system, systemid, pls, sourcetype, sourceuse, win, wrnum, sourcecode,sourceid = [],[],[],[],[],[],[],[],[],[]\n",
    "system_id = []\n",
    "\n",
    "for f in range(len(files)): \n",
    "    text = open(files[f]).read()\n",
    "    systemname = gettext('System  Name:','Address:',text)\n",
    "    sid = gettext('Public Water System ID:','DEQ',text)\n",
    "    srcind = [m.start() for m in re.finditer('Source Summary', text)]\n",
    "    \n",
    "    prefix = os.path.split(files[f])[1][0:3]\n",
    "    html = 'http://www.waterrights.utah.gov/cgi-bin/wuseview.exe?Modinfo='+ prefix +'view&SYSTEM_ID='\n",
    "    \n",
    "    sysnum.append(int(os.path.split(files[f])[1][3:9]))\n",
    "    linknum = int(os.path.split(files[f])[1][3:9])\n",
    "    systype.append(prefix)\n",
    "    link.append(html+str(linknum))\n",
    "    \n",
    "    systid = prefix+'-'+str(linknum).zfill(5)\n",
    "    \n",
    "    system_id.append(systid)\n",
    "    sysname.append(gettext('System  Name:','Address:',text))\n",
    "    city.append(gettext('City:','State:',text))\n",
    "    county.append(gettext('County:','Primary Use:',text))\n",
    "    syscat.append(gettext('Primary Use:','Standard',text))\n",
    "    huc.append(gettext('Hydro Unit Code:','Public',text))\n",
    "    pwsid.append(gettext('Public Water System ID:','DEQ',text))\n",
    "    deqcat.append(gettext('DEQ System Category:','\\n',text))\n",
    "    indcode.append(gettext('Standard Industrial Code:','Dual',text))\n",
    "    \n",
    "    numberofsources.append(len(srcind))\n",
    "    \n",
    "    for i in range(len(srcind)):\n",
    "\n",
    "        if i == len(srcind)-1:\n",
    "            subtext = text[srcind[i]:-1]\n",
    "        else:\n",
    "            subtext = text[srcind[i]:srcind[i+1]]\n",
    "            \n",
    "        source.append(gettext('Source Name:','\\n',subtext))\n",
    "        pls.append(gettext('PLS Location:','\\n',subtext))\n",
    "        sourcetype.append(gettext('Source Type:','\\n',subtext))\n",
    "        sourceuse.append(gettext('Primary Use:','\\n',subtext))\n",
    "        win.append(gettext('Well ID Number:','(C',subtext))\n",
    "        sourcecode.append(gettext('DEHN Source Code:','\\n',subtext))\n",
    "        wrnum.append(gettext('Water Right Numbers:','\\n',subtext))\n",
    "        system.append(systemname)\n",
    "        systemid.append(sid)\n",
    "        srcid = systid +'-'+str(i).zfill(2)\n",
    "        sourceid.append(srcid)\n",
    "        \n",
    "        table = gettext(' Source Record (ACFT)\\r\\n','\\r\\n \\r',subtext)\n",
    "        table = re.sub('Master +Meter','MasterMeter',str(table))\n",
    "        table = re.sub('Master +Met','MasterMeter',table)\n",
    "        table = re.sub('Individual +Meters','IndividualMeters',table)\n",
    "        table = re.sub('Measuring +Method','MeasuringMethod',table)\n",
    "        table = tparser(table) \n",
    "        rv = table.split('\\n')\n",
    "        b = []\n",
    "        for j in range(len(rv)):    \n",
    "            if rv[j].count(',') > 15:\n",
    "                rb = rv[j].split(',')\n",
    "                rb.insert(15,'\\n')\n",
    "                b.append(','.join(rb))\n",
    "            elif rv[j].count(',')==15:\n",
    "                b.append(rv[j])  \n",
    "            elif rv[j].count(',') < 15 and rv[j].count(',') > 4:\n",
    "                b.append(rv[j] + ','*(15-rv[j].count(',')))\n",
    "            else:\n",
    "                pass\n",
    "        rev = '\\n'.join(b)\n",
    "        try:\n",
    "            sourcet[srcid] = pd.read_csv(StringIO(rev))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    usetable = gettext(' Annual Use Info (Acft) \\r\\n','\\r\\n \\r',text)\n",
    "    usetable = tparser(usetable)\n",
    "    try:\n",
    "        use[systid] = pd.read_csv(StringIO(usetable))\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    conntable = gettext(' Annual Connection Info\\r\\n','\\r\\n\\r\\n ',text)\n",
    "    conntable = tparser(conntable)\n",
    "    try:\n",
    "        conn[systid] = pd.read_csv(StringIO(conntable))\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sysdict = {'systype':systype, 'systemnum': sysnum, 'link':link, 'sysname':sysname, 'city':city, \n",
    "           'county':county, 'syscat':syscat, 'indust code':indcode, 'number of sources':numberofsources,\n",
    "          'huc':huc, 'pwsid':pwsid,'deqcat':deqcat, 'systemid':system_id}\n",
    "\n",
    "systems = pd.DataFrame(sysdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sourcedict = {'source':source, 'system id': systemid, 'system':system, 'pls':pls, 'source type': sourcetype,\n",
    "          'source use':sourceuse, 'win':win, 'wrnum':wrnum, 'DEHN source id':sourcecode, 'source id':sourceid}\n",
    "\n",
    "sources = pd.DataFrame(sourcedict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sourcetake = pd.concat(sourcet)\n",
    "sourcetake.reset_index(inplace=True)\n",
    "sourcetake.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "sourcetake.set_index(['systemid','Year'],inplace=True)\n",
    "sourcetake.drop(['level_1','Measuring','MeasuringMethod','Unnamed: 15','Mea','Meth','Ann'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srctake = sourcetake.stack().to_frame()\n",
    "srctake.rename(columns={'0':'Use (ac-ft)'},inplace=True)\n",
    "srctake.reset_index(inplace=True)\n",
    "srctake['Year'] = pd.to_numeric(srctake['Year'],errors='coerce')\n",
    "srctake = srctake[(srctake['Year']<=datetime.today().year)&(srctake['Year']>=1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srctake = srctake[srctake['level_2'].isin(['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'])]\n",
    "srctake['my'] = srctake[['Year','level_2']].apply(lambda x: pd.to_datetime(str(int(x[0]))+' '+str(x[1]), format='%Y %b'),1)\n",
    "srctake.columns = ['sourceid','Year','Month','Use','datetime']\n",
    "srctake['systemid'] = srctake['sourceid'].apply(lambda x: str(x)[0:9],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuse = pd.concat(use)\n",
    "systemuse.reset_index(inplace=True)\n",
    "systemuse.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "systemuse.drop(['level_1','Tota','nan'],axis=1,inplace=True)\n",
    "cols = ['Commercial','Domestic','Industrial','Institutnl','Other','Stock','Unmetered','Wholesale']\n",
    "for col in cols:\n",
    "    systemuse[col] = pd.to_numeric(systemuse[col], errors='coerce')\n",
    "systemuse['Total'] = pd.to_numeric(systemuse['Total'])\n",
    "systemuse['Total1'] = systemuse[cols].sum(axis=1)\n",
    "systemuse['Year'] = pd.to_numeric(systemuse['Year'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "systemuseData = systemuse[systemuse['Year']<2017]\n",
    "systemuseData = systemuse[systemuse.Total < 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append Existing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.waterrights.utah.gov/cgi-bin/pubdump.exe?DBNAME=WELLDB&SECURITYKEY=wrt2012access<br/>\n",
    "http://www.waterrights.utah.gov/cgi-bin/pubdump.exe?DBNAME=WRDB&SECURITYKEY=wrt2012access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlactivity = pd.read_csv(route+'wlactivity.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replacements = {'\"\"':'\\\"\"', 'temp':'bob', 'garbage':'nothing'}\n",
    "\n",
    "with open(route+'wlcomments.txt') as infile, open(route+'wlcomments1.txt', 'w') as outfile:\n",
    "    for line in infile:\n",
    "        for src, target in replacements.iteritems():\n",
    "            line = line.replace(src, target)\n",
    "        outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wlcomments = pd.read_csv(route+'wlcomments.txt',delimiter='\\t',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['win','finishedDiameter','drillingMethod','totalDepth','finishedDepth','screenDepth','geologicLog']\n",
    "wlwellfeatures = pd.read_csv(route+'wlwellfeatures.txt',header = None, \n",
    "                             names = cols, delimiter='\\t',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['recordId', 'win', 'wlDate', 'wlTime', 'wlDepth', 'wlStatus', 'wlMethod']       \n",
    "wlWaterLevel = pd.read_csv(route+'wlWaterLevel.txt',header = None, names = cols, delimiter='\\t',error_bad_lines=False,)\n",
    "\n",
    "def timefix(x):\n",
    "    if x[1]=='' or str(x[1]) == np.nan or str(x[1]) =='nan':\n",
    "        x[1]='00:00:00'\n",
    "    return pd.to_datetime(str(x[0])+' '+str(x[1]), format='%Y%m%d %H:%M:%S',errors='coerce',exact='false')\n",
    "\n",
    "\n",
    "wlWaterLevel['datetime'] = wlWaterLevel[['wlDate','wlTime']].apply(lambda x: timefix(x),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordId</th>\n",
       "      <th>win</th>\n",
       "      <th>wlDate</th>\n",
       "      <th>wlTime</th>\n",
       "      <th>wlDepth</th>\n",
       "      <th>wlStatus</th>\n",
       "      <th>wlMethod</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131180</td>\n",
       "      <td>3440</td>\n",
       "      <td>20140923</td>\n",
       "      <td>10:41:38</td>\n",
       "      <td>58.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>sounder</td>\n",
       "      <td>2014-09-23 10:41:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131181</td>\n",
       "      <td>436593</td>\n",
       "      <td>20140923</td>\n",
       "      <td>10:46:43</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>elec sounder</td>\n",
       "      <td>2014-09-23 10:46:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131182</td>\n",
       "      <td>437767</td>\n",
       "      <td>20140924</td>\n",
       "      <td>15:29:56</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>flowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-24 15:29:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131183</td>\n",
       "      <td>437898</td>\n",
       "      <td>20140924</td>\n",
       "      <td>15:46:23</td>\n",
       "      <td>235.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>probe</td>\n",
       "      <td>2014-09-24 15:46:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131184</td>\n",
       "      <td>437905</td>\n",
       "      <td>20140925</td>\n",
       "      <td>11:10:15</td>\n",
       "      <td>120.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>sounder</td>\n",
       "      <td>2014-09-25 11:10:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131185</td>\n",
       "      <td>437930</td>\n",
       "      <td>20140925</td>\n",
       "      <td>11:12:10</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>flowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-09-25 11:12:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>131187</td>\n",
       "      <td>437917</td>\n",
       "      <td>20140929</td>\n",
       "      <td>14:57:42</td>\n",
       "      <td>270.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>water tape</td>\n",
       "      <td>2014-09-29 14:57:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>131188</td>\n",
       "      <td>437841</td>\n",
       "      <td>20140930</td>\n",
       "      <td>13:54:00</td>\n",
       "      <td>170.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>TAPE</td>\n",
       "      <td>2014-09-30 13:54:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>131189</td>\n",
       "      <td>437988</td>\n",
       "      <td>20141001</td>\n",
       "      <td>13:31:50</td>\n",
       "      <td>38.50000</td>\n",
       "      <td>topofeight</td>\n",
       "      <td>wlm</td>\n",
       "      <td>2014-10-01 13:31:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>131190</td>\n",
       "      <td>437974</td>\n",
       "      <td>20141001</td>\n",
       "      <td>13:33:08</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>topofeight</td>\n",
       "      <td>wlm</td>\n",
       "      <td>2014-10-01 13:33:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>131191</td>\n",
       "      <td>438005</td>\n",
       "      <td>20141006</td>\n",
       "      <td>07:35:15</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>sounder</td>\n",
       "      <td>2014-10-06 07:35:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>131192</td>\n",
       "      <td>437967</td>\n",
       "      <td>20141006</td>\n",
       "      <td>07:39:30</td>\n",
       "      <td>504.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>e-tape</td>\n",
       "      <td>2014-10-06 07:39:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>131193</td>\n",
       "      <td>437946</td>\n",
       "      <td>20141006</td>\n",
       "      <td>07:41:30</td>\n",
       "      <td>24.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>e-tape</td>\n",
       "      <td>2014-10-06 07:41:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>131196</td>\n",
       "      <td>437964</td>\n",
       "      <td>20141006</td>\n",
       "      <td>13:27:03</td>\n",
       "      <td>148.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>FLOAT</td>\n",
       "      <td>2014-10-06 13:27:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>131200</td>\n",
       "      <td>437999</td>\n",
       "      <td>20141014</td>\n",
       "      <td>13:18:49</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>tape</td>\n",
       "      <td>2014-10-14 13:18:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>131201</td>\n",
       "      <td>438003</td>\n",
       "      <td>20141014</td>\n",
       "      <td>13:21:01</td>\n",
       "      <td>324.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>sounder</td>\n",
       "      <td>2014-10-14 13:21:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>131202</td>\n",
       "      <td>437927</td>\n",
       "      <td>20141014</td>\n",
       "      <td>13:22:54</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>elec sounder</td>\n",
       "      <td>2014-10-14 13:22:54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>131203</td>\n",
       "      <td>438012</td>\n",
       "      <td>20141014</td>\n",
       "      <td>13:58:41</td>\n",
       "      <td>46.00000</td>\n",
       "      <td>topofeight</td>\n",
       "      <td>wlm</td>\n",
       "      <td>2014-10-14 13:58:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>131205</td>\n",
       "      <td>437700</td>\n",
       "      <td>20141016</td>\n",
       "      <td>10:56:01</td>\n",
       "      <td></td>\n",
       "      <td>flowing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-16 10:56:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>131208</td>\n",
       "      <td>437992</td>\n",
       "      <td>20141016</td>\n",
       "      <td>11:04:21</td>\n",
       "      <td>115.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>probe</td>\n",
       "      <td>2014-10-16 11:04:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>131217</td>\n",
       "      <td>437873</td>\n",
       "      <td>20141022</td>\n",
       "      <td>09:27:24</td>\n",
       "      <td>132.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>elec tape</td>\n",
       "      <td>2014-10-22 09:27:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>131221</td>\n",
       "      <td>438051</td>\n",
       "      <td>20141027</td>\n",
       "      <td>15:32:35</td>\n",
       "      <td>100.00000</td>\n",
       "      <td>GROUND</td>\n",
       "      <td>TAPE</td>\n",
       "      <td>2014-10-27 15:32:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>131222</td>\n",
       "      <td>432692</td>\n",
       "      <td>20141027</td>\n",
       "      <td>15:34:49</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014-10-27 15:34:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>131223</td>\n",
       "      <td>438075</td>\n",
       "      <td>20141027</td>\n",
       "      <td>15:38:22</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>tape</td>\n",
       "      <td>2014-10-27 15:38:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>131225</td>\n",
       "      <td>437991</td>\n",
       "      <td>20141027</td>\n",
       "      <td>16:13:50</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>tape</td>\n",
       "      <td>2014-10-27 16:13:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>131226</td>\n",
       "      <td>438036</td>\n",
       "      <td>20141027</td>\n",
       "      <td>16:21:05</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>tape</td>\n",
       "      <td>2014-10-27 16:21:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>131228</td>\n",
       "      <td>437904</td>\n",
       "      <td>20141027</td>\n",
       "      <td>16:37:12</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>m-scope</td>\n",
       "      <td>2014-10-27 16:37:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>131229</td>\n",
       "      <td>437914</td>\n",
       "      <td>20141027</td>\n",
       "      <td>16:39:03</td>\n",
       "      <td>439.00000</td>\n",
       "      <td>toc</td>\n",
       "      <td>e-tape</td>\n",
       "      <td>2014-10-27 16:39:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>131230</td>\n",
       "      <td>438021</td>\n",
       "      <td>20141027</td>\n",
       "      <td>16:41:11</td>\n",
       "      <td>10.00000</td>\n",
       "      <td>ground</td>\n",
       "      <td>tape</td>\n",
       "      <td>2014-10-27 16:41:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>131231</td>\n",
       "      <td>437995</td>\n",
       "      <td>20141027</td>\n",
       "      <td>16:43:07</td>\n",
       "      <td>255.60000</td>\n",
       "      <td>toc</td>\n",
       "      <td>e-tape</td>\n",
       "      <td>2014-10-27 16:43:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32512</th>\n",
       "      <td>111698</td>\n",
       "      <td>16151</td>\n",
       "      <td>19970719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Probe</td>\n",
       "      <td>1997-07-19 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32513</th>\n",
       "      <td>111699</td>\n",
       "      <td>16152</td>\n",
       "      <td>19970731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-07-31 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32514</th>\n",
       "      <td>111700</td>\n",
       "      <td>16153</td>\n",
       "      <td>19970424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Probe</td>\n",
       "      <td>1997-04-24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32515</th>\n",
       "      <td>111701</td>\n",
       "      <td>16154</td>\n",
       "      <td>19860730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1986-07-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32516</th>\n",
       "      <td>111702</td>\n",
       "      <td>16156</td>\n",
       "      <td>19970729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.60000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-07-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32517</th>\n",
       "      <td>111703</td>\n",
       "      <td>16158</td>\n",
       "      <td>19970718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-07-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32518</th>\n",
       "      <td>111704</td>\n",
       "      <td>16160</td>\n",
       "      <td>19760422</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1976-04-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32519</th>\n",
       "      <td>111705</td>\n",
       "      <td>16162</td>\n",
       "      <td>19460820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946-08-20 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32520</th>\n",
       "      <td>111706</td>\n",
       "      <td>16163</td>\n",
       "      <td>19870530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1987-05-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32521</th>\n",
       "      <td>111707</td>\n",
       "      <td>16165</td>\n",
       "      <td>19461005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1946-10-05 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32522</th>\n",
       "      <td>111708</td>\n",
       "      <td>16167</td>\n",
       "      <td>19811028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1981-10-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32523</th>\n",
       "      <td>111709</td>\n",
       "      <td>16168</td>\n",
       "      <td>19800624</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1980-06-24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32524</th>\n",
       "      <td>111710</td>\n",
       "      <td>16169</td>\n",
       "      <td>19690424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1969-04-24 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32525</th>\n",
       "      <td>111711</td>\n",
       "      <td>16170</td>\n",
       "      <td>19970718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-07-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32526</th>\n",
       "      <td>111712</td>\n",
       "      <td>16171</td>\n",
       "      <td>19970911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997-09-11 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32527</th>\n",
       "      <td>111713</td>\n",
       "      <td>16172</td>\n",
       "      <td>19970807</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-08-07 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32528</th>\n",
       "      <td>111714</td>\n",
       "      <td>16173</td>\n",
       "      <td>19970728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-07-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32529</th>\n",
       "      <td>111715</td>\n",
       "      <td>16174</td>\n",
       "      <td>19970721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Probe</td>\n",
       "      <td>1997-07-21 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32530</th>\n",
       "      <td>111716</td>\n",
       "      <td>16175</td>\n",
       "      <td>19970802</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-08-02 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32531</th>\n",
       "      <td>111717</td>\n",
       "      <td>16176</td>\n",
       "      <td>19970722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-07-22 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32532</th>\n",
       "      <td>111718</td>\n",
       "      <td>16177</td>\n",
       "      <td>19980818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>182.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1998-08-18 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32533</th>\n",
       "      <td>111719</td>\n",
       "      <td>16178</td>\n",
       "      <td>19971029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-10-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32534</th>\n",
       "      <td>111720</td>\n",
       "      <td>16180</td>\n",
       "      <td>19730801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1973-08-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32535</th>\n",
       "      <td>111721</td>\n",
       "      <td>16181</td>\n",
       "      <td>19831128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1983-11-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32536</th>\n",
       "      <td>111722</td>\n",
       "      <td>16182</td>\n",
       "      <td>19820801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1982-08-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32537</th>\n",
       "      <td>111723</td>\n",
       "      <td>16184</td>\n",
       "      <td>19970730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>110.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-07-30 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32538</th>\n",
       "      <td>111724</td>\n",
       "      <td>16185</td>\n",
       "      <td>19970813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-08-13 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32539</th>\n",
       "      <td>111725</td>\n",
       "      <td>16186</td>\n",
       "      <td>19970829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-08-29 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32540</th>\n",
       "      <td>111726</td>\n",
       "      <td>16187</td>\n",
       "      <td>19970828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Tape</td>\n",
       "      <td>1997-08-28 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32541</th>\n",
       "      <td>111727</td>\n",
       "      <td>16189</td>\n",
       "      <td>19970823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.00000</td>\n",
       "      <td>Static</td>\n",
       "      <td>Other</td>\n",
       "      <td>1997-08-23 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32542 rows  8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       recordId     win    wlDate    wlTime               wlDepth    wlStatus  \\\n",
       "0        131180    3440  20140923  10:41:38              58.00000         toc   \n",
       "1        131181  436593  20140923  10:46:43               7.00000         toc   \n",
       "2        131182  437767  20140924  15:29:56               0.00000     flowing   \n",
       "3        131183  437898  20140924  15:46:23             235.00000      ground   \n",
       "4        131184  437905  20140925  11:10:15             120.00000      ground   \n",
       "5        131185  437930  20140925  11:12:10               0.00000     flowing   \n",
       "6        131187  437917  20140929  14:57:42             270.00000         toc   \n",
       "7        131188  437841  20140930  13:54:00             170.00000      ground   \n",
       "8        131189  437988  20141001  13:31:50              38.50000  topofeight   \n",
       "9        131190  437974  20141001  13:33:08              42.00000  topofeight   \n",
       "10       131191  438005  20141006  07:35:15             148.00000      ground   \n",
       "11       131192  437967  20141006  07:39:30             504.00000         toc   \n",
       "12       131193  437946  20141006  07:41:30              24.00000         toc   \n",
       "13       131196  437964  20141006  13:27:03             148.00000      ground   \n",
       "14       131200  437999  20141014  13:18:49              12.00000      ground   \n",
       "15       131201  438003  20141014  13:21:01             324.00000      ground   \n",
       "16       131202  437927  20141014  13:22:54              14.00000         toc   \n",
       "17       131203  438012  20141014  13:58:41              46.00000  topofeight   \n",
       "18       131205  437700  20141016  10:56:01                           flowing   \n",
       "19       131208  437992  20141016  11:04:21             115.00000      ground   \n",
       "20       131217  437873  20141022  09:27:24             132.00000         toc   \n",
       "21       131221  438051  20141027  15:32:35             100.00000      GROUND   \n",
       "22       131222  432692  20141027  15:34:49              40.00000         NaN   \n",
       "23       131223  438075  20141027  15:38:22              20.00000      ground   \n",
       "24       131225  437991  20141027  16:13:50              25.00000      ground   \n",
       "25       131226  438036  20141027  16:21:05              15.00000      ground   \n",
       "26       131228  437904  20141027  16:37:12              99.00000         toc   \n",
       "27       131229  437914  20141027  16:39:03             439.00000         toc   \n",
       "28       131230  438021  20141027  16:41:11              10.00000      ground   \n",
       "29       131231  437995  20141027  16:43:07             255.60000         toc   \n",
       "...         ...     ...       ...       ...                   ...         ...   \n",
       "32512    111698   16151  19970719       NaN             195.00000         NaN   \n",
       "32513    111699   16152  19970731       NaN              31.00000      Static   \n",
       "32514    111700   16153  19970424       NaN              36.00000      Static   \n",
       "32515    111701   16154  19860730       NaN               4.00000      Static   \n",
       "32516    111702   16156  19970729       NaN               3.60000      Static   \n",
       "32517    111703   16158  19970718       NaN               0.00000         NaN   \n",
       "32518    111704   16160  19760422       NaN              75.00000      Static   \n",
       "32519    111705   16162  19460820       NaN              42.00000      Static   \n",
       "32520    111706   16163  19870530       NaN              15.00000      Static   \n",
       "32521    111707   16165  19461005       NaN              14.00000      Static   \n",
       "32522    111708   16167  19811028       NaN              40.00000      Static   \n",
       "32523    111709   16168  19800624       NaN              37.00000      Static   \n",
       "32524    111710   16169  19690424       NaN              25.00000      Static   \n",
       "32525    111711   16170  19970718       NaN              33.00000      Static   \n",
       "32526    111712   16171  19970911       NaN              90.00000      Static   \n",
       "32527    111713   16172  19970807       NaN              40.00000      Static   \n",
       "32528    111714   16173  19970728       NaN               9.00000      Static   \n",
       "32529    111715   16174  19970721       NaN              45.00000      Static   \n",
       "32530    111716   16175  19970802       NaN              81.00000      Static   \n",
       "32531    111717   16176  19970722       NaN              70.00000      Static   \n",
       "32532    111718   16177  19980818       NaN             182.00000      Static   \n",
       "32533    111719   16178  19971029       NaN               1.50000      Static   \n",
       "32534    111720   16180  19730801       NaN              13.00000      Static   \n",
       "32535    111721   16181  19831128       NaN              30.00000      Static   \n",
       "32536    111722   16182  19820801       NaN              30.00000      Static   \n",
       "32537    111723   16184  19970730       NaN             110.00000      Static   \n",
       "32538    111724   16185  19970813       NaN              20.00000      Static   \n",
       "32539    111725   16186  19970829       NaN              17.00000      Static   \n",
       "32540    111726   16187  19970828       NaN              28.00000      Static   \n",
       "32541    111727   16189  19970823       NaN              67.00000      Static   \n",
       "\n",
       "           wlMethod            datetime  \n",
       "0           sounder 2014-09-23 10:41:38  \n",
       "1      elec sounder 2014-09-23 10:46:43  \n",
       "2               NaN 2014-09-24 15:29:56  \n",
       "3             probe 2014-09-24 15:46:23  \n",
       "4           sounder 2014-09-25 11:10:15  \n",
       "5               NaN 2014-09-25 11:12:10  \n",
       "6        water tape 2014-09-29 14:57:42  \n",
       "7              TAPE 2014-09-30 13:54:00  \n",
       "8               wlm 2014-10-01 13:31:50  \n",
       "9               wlm 2014-10-01 13:33:08  \n",
       "10          sounder 2014-10-06 07:35:15  \n",
       "11           e-tape 2014-10-06 07:39:30  \n",
       "12           e-tape 2014-10-06 07:41:30  \n",
       "13            FLOAT 2014-10-06 13:27:03  \n",
       "14             tape 2014-10-14 13:18:49  \n",
       "15          sounder 2014-10-14 13:21:01  \n",
       "16     elec sounder 2014-10-14 13:22:54  \n",
       "17              wlm 2014-10-14 13:58:41  \n",
       "18              NaN 2014-10-16 10:56:01  \n",
       "19            probe 2014-10-16 11:04:21  \n",
       "20        elec tape 2014-10-22 09:27:24  \n",
       "21             TAPE 2014-10-27 15:32:35  \n",
       "22              NaN 2014-10-27 15:34:49  \n",
       "23             tape 2014-10-27 15:38:22  \n",
       "24             tape 2014-10-27 16:13:50  \n",
       "25             tape 2014-10-27 16:21:05  \n",
       "26          m-scope 2014-10-27 16:37:12  \n",
       "27           e-tape 2014-10-27 16:39:03  \n",
       "28             tape 2014-10-27 16:41:11  \n",
       "29           e-tape 2014-10-27 16:43:07  \n",
       "...             ...                 ...  \n",
       "32512         Probe 1997-07-19 00:00:00  \n",
       "32513         Other 1997-07-31 00:00:00  \n",
       "32514         Probe 1997-04-24 00:00:00  \n",
       "32515           NaN 1986-07-30 00:00:00  \n",
       "32516         Other 1997-07-29 00:00:00  \n",
       "32517           NaN 1997-07-18 00:00:00  \n",
       "32518           NaN 1976-04-22 00:00:00  \n",
       "32519           NaN 1946-08-20 00:00:00  \n",
       "32520           NaN 1987-05-30 00:00:00  \n",
       "32521           NaN 1946-10-05 00:00:00  \n",
       "32522           NaN 1981-10-28 00:00:00  \n",
       "32523           NaN 1980-06-24 00:00:00  \n",
       "32524           NaN 1969-04-24 00:00:00  \n",
       "32525         Other 1997-07-18 00:00:00  \n",
       "32526           NaN 1997-09-11 00:00:00  \n",
       "32527         Other 1997-08-07 00:00:00  \n",
       "32528         Other 1997-07-28 00:00:00  \n",
       "32529         Probe 1997-07-21 00:00:00  \n",
       "32530         Other 1997-08-02 00:00:00  \n",
       "32531         Other 1997-07-22 00:00:00  \n",
       "32532         Other 1998-08-18 00:00:00  \n",
       "32533         Other 1997-10-29 00:00:00  \n",
       "32534           NaN 1973-08-01 00:00:00  \n",
       "32535           NaN 1983-11-28 00:00:00  \n",
       "32536           NaN 1982-08-01 00:00:00  \n",
       "32537         Other 1997-07-30 00:00:00  \n",
       "32538         Other 1997-08-13 00:00:00  \n",
       "32539         Other 1997-08-29 00:00:00  \n",
       "32540          Tape 1997-08-28 00:00:00  \n",
       "32541         Other 1997-08-23 00:00:00  \n",
       "\n",
       "[32542 rows x 8 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlWaterLevel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following converts the harvested data to water rights text format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "quer = \"SELECT * FROM water_rights_data.waterlevels\"\n",
    "wls = pd.read_sql_query(sql=quer,con=engine)\n",
    "wls['Date'] = wls['Date'].apply(lambda x: pd.to_datetime(x, errors='coerce'), 1)\n",
    "wls = wls[(wls['Date'].notnull()) & (wls['Date'] >= pd.datetime(1900,1,1))]\n",
    "wls['wlDate'] = wls['Date'].apply(lambda x: \"{:%Y%m%d}\".format(x),1)\n",
    "wls.columns = ['win','datetime','wlDepth','wlStatus', u'wlDate']\n",
    "wlWL = pd.concat([wls,wlWaterLevel],axis=0)\n",
    "wlWL.drop(['datetime'],axis=1,inplace=True)\n",
    "wlWL['wlStatus']=wlWL['wlStatus'].apply(lambda x: str(x).title(),1)\n",
    "wlWL.sort_values(by=['win','recordId'], inplace=True)\n",
    "wlWL.drop_duplicates(subset=['win','wlDate','wlDepth'],keep='first',inplace=True)\n",
    "wlWL.to_csv(route+'wlWaterLevel_v1.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following combines existing water rights data with the harvested data for upload to arcgis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'Date', u'Level', u'Method', u'WIN'], dtype='object')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quer = \"SELECT * FROM water_rights_data.waterlevels\"\n",
    "wls = pd.read_sql_query(sql=quer,con=engine)\n",
    "wls['Date'] = wls['Date'].apply(lambda x: pd.to_datetime(x, errors='coerce'), 1)\n",
    "wls = wls[(wls['Date'].notnull())]\n",
    "wls['Level'] = wls['Level'].apply(lambda x: round(pd.to_numeric(x, errors='coerce'),2),1)\n",
    "wrData = wlWaterLevel.drop(['recordId','wlTime','wlMethod','wlDate'],axis=1)\n",
    "wrData.columns = ['WIN','Level','Method','Date']\n",
    "wrData['Level'] = wrData['Level'].apply(lambda x: round(pd.to_numeric(x, errors='coerce'),2),1)\n",
    "waterlevels = pd.concat([wls,wrData],axis=0)\n",
    "waterlevels['Method'] = waterlevels['Method'].apply(lambda x: str(x).title(),1)\n",
    "\n",
    "waterlevels.sort_values(by=['WIN','Date'], inplace=True)\n",
    "waterlevels.drop_duplicates(subset=['WIN','Date'],keep='last',inplace=True)\n",
    "waterlevels = waterlevels[waterlevels['Date'].notnull()]\n",
    "waterlevels.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "waterlevels.columns = ['Date', 'Level', 'wlMethod', 'WIN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connections = pd.concat(conn)\n",
    "connections.reset_index(inplace=True)\n",
    "connections.rename(columns={'level_0':'systemid'},inplace=True)\n",
    "connections.drop(['level_1','nan'],axis=1,inplace=True)\n",
    "connections = connections[(connections['Year']<datetime.today().year)&(connections['Year']>1830)]\n",
    "connections = connections[connections.Total < 100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MySQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This must be done after scraping or you will throw a host error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engineroute = \"H:/Google Drive/WORK/Groundwater Chemistry\"\n",
    "#engineroute = \"C:/Users/Brooke/Downloads/\"\n",
    "sys.path.append(engineroute)\n",
    "import enginegetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "engine = enginegetter.getEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems and Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the systems made up of the sources.  They are often cities or water agencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "systems.to_sql(con=engine, name='systems', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the water use sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sources.to_sql(con=engine, name='sources', if_exists='replace', flavor='mysql', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts the amount of water use by each source in ac-ft/mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "srctake.to_sql(con=engine, name='sourceuse', if_exists='replace', flavor='mysql',chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts the amount of water use by each system in ac-ft/yr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuseData.to_sql(con=engine, name='systemuse', if_exists='replace', flavor='mysql',chunksize=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depicts number of connections in system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connections.to_sql(con=engine, name='systemconnections', if_exists='replace', flavor='mysql')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "waterlevels.to_sql(con=engine, name='waterlevels', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "borehole.to_sql(con=engine, name='borehole', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driller.to_sql(con=engine, name='driller', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lithlog.to_sql(con=engine, name='lithlog', if_exists='replace', flavor='mysql',index=False, chunksize=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "construction.to_sql(con=engine, name='construction', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "screendf.to_sql(con=engine, name='wellscreens', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wellTrans.to_sql(con=engine, name='pumpingtests', if_exists='replace', flavor='mysql',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## ArcPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Locate ArcPy and add it to the path\n",
    "Created on 13 Feb 2015\n",
    "@author: Jamesramm\n",
    "https://github.com/JamesRamm/archook/blob/master/archook.py\n",
    "'''\n",
    "import _winreg\n",
    "import sys\n",
    "from os import path\n",
    "def locate_arcgis():\n",
    "  '''\n",
    "  Find the path to the ArcGIS Desktop installation.\n",
    "  Keys to check:\n",
    "  HLKM/SOFTWARE/ESRI/ArcGIS 'RealVersion' - will give the version, then we can use\n",
    "  that to go to\n",
    "  HKLM/SOFTWARE/ESRI/DesktopXX.X 'InstallDir'. Where XX.X is the version\n",
    "  We may need to check HKLM/SOFTWARE/Wow6432Node/ESRI instead\n",
    "  '''\n",
    "  try:\n",
    "    key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                          'SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\ArcGIS', 0)\n",
    "\n",
    "    version = _winreg.QueryValueEx(key, \"RealVersion\")[0][:4]\n",
    "\n",
    "    key_string = \"SOFTWARE\\\\Wow6432Node\\\\ESRI\\\\Desktop{0}\".format(version)\n",
    "    desktop_key = _winreg.OpenKey(_winreg.HKEY_LOCAL_MACHINE,\n",
    "                                  key_string, 0)\n",
    "\n",
    "    install_dir = _winreg.QueryValueEx(desktop_key, \"InstallDir\")[0]\n",
    "    return install_dir\n",
    "  except WindowsError:\n",
    "    raise ImportError(\"Could not locate the ArcGIS directory on this machine\")\n",
    "\n",
    "def get_arcpy():  \n",
    "  '''\n",
    "  Allows arcpy to imported on 'unmanaged' python installations (i.e. python installations\n",
    "  arcgis is not aware of).\n",
    "  Gets the location of arcpy and related libs and adds it to sys.path\n",
    "  '''\n",
    "  install_dir = locate_arcgis()  \n",
    "  arcpy = path.join(install_dir, \"arcpy\")\n",
    "  # Check we have the arcpy directory.\n",
    "  if not path.exists(arcpy):\n",
    "    raise ImportError(\"Could not find arcpy directory in {0}\".format(install_dir))\n",
    "\n",
    "  # First check if we have a bin64 directory - this exists when arcgis is 64bit\n",
    "  bin_dir = path.join(install_dir, \"bin64\")\n",
    "  if not path.exists(bin_dir):\n",
    "    # Fall back to regular 'bin' dir otherwise.\n",
    "    bin_dir = path.join(install_dir, \"bin\")\n",
    "\n",
    "  scripts = path.join(install_dir, \"ArcToolbox\", \"Scripts\")  \n",
    "  sys.path.extend([arcpy, bin_dir, scripts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "get_arcpy()\n",
    "import arcpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileloc = r'H:/GIS/WR_DATA.gdb/'\n",
    "\n",
    "def df2gdb(df,fileloc,name):\n",
    "    x = np.array(np.rec.fromrecords(df.values))\n",
    "    names = df.dtypes.index.tolist()\n",
    "    names = [str(i) for i in names]\n",
    "    x.dtype.names = tuple(names)\n",
    "    arcpy.da.NumPyArrayToTable(x, fileloc+name)\n",
    "\n",
    "def df2csv2gdb(df,fileloc,csvloc,name,ind=False):\n",
    "    df.to_csv(csvloc,index=ind)\n",
    "    arcpy.TableToTable_conversion(csvloc, fileloc, name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Systems and Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(systems,fileloc,'systems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(sources,fileloc,'sources')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(systemuseData,fileloc,'systemuse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Well Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2csv2gdb(waterlevels,fileloc,r'H:/GIS/waterlevels.csv','waterlevels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2gdb(borehole,fileloc,'borehole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(driller,fileloc,'driller')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df2csv2gdb(lithlog,fileloc,r'C:/GIS/lithlogs.csv','lithlogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(construction,fileloc,'construction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(screendf,fileloc,'screen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(wellTrans,fileloc,'spCapTrans')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2gdb(connections,fileloc,'connections')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot and Analyze Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "systemuseData.groupby('Year')[['Total','Domestic','Industrial','Commercial']].sum().plot()\n",
    "plt.xlim(1980,2020)\n",
    "plt.ylabel('Use (ac-ft)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "systemuseData.groupby('Year')['Total'].sum().plot()\n",
    "plt.xlim(1980,2020)\n",
    "plt.ylabel('Use (ac-ft)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "writer = pd.ExcelWriter('C:\\\\PROJECTS\\\\WR_DATA\\\\' + 'systems_and_sources.xlsx', engine='xlsxwriter')\n",
    "\n",
    "# Convert the dataframe to an XlsxWriter Excel object.\n",
    "systems.to_excel(writer, sheet_name='systems')\n",
    "sources.to_excel(writer, sheet_name='sources')\n",
    "srctakeData.to_excel(writer, sheet_name='sourcetake')\n",
    "systemuseData.to_excel(writer, sheet_name='system_use')\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
